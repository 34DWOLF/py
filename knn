import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LinearRegression
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.metrics import mean_squared_error

# ---------- STEP 1: Helper functions ----------

def preprocess(df):
    df = df.copy()
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date').reset_index(drop=True)
    df['Month'] = df['Date'].dt.month
    return df

def deseasonalize_and_detrend(df, period=12):
    df = df.copy()
    decomposition = seasonal_decompose(df['Value'], period=period, model='additive', extrapolate_trend='freq')
    df['trend'] = decomposition.trend
    df['seasonal'] = decomposition.seasonal
    df['resid'] = df['Value'] - df['trend'] - df['seasonal']
    df['trend'].fillna(method='bfill', inplace=True)
    df['trend'].fillna(method='ffill', inplace=True)
    df['resid'].fillna(0, inplace=True)
    return df

def add_lag_features(df, target_col='resid', lags=[1,2,3]):
    df = df.copy()
    for lag in lags:
        df[f'lag_{lag}'] = df[target_col].shift(lag)
    return df.dropna()

def train_knn_on_resid(df, regressors=['R1','R2'], lags=[1,2,3], n_neighbors=5):
    features = regressors + [f'lag_{l}' for l in lags]
    X = df[features]
    y = df['resid']
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    model = KNeighborsRegressor(n_neighbors=n_neighbors)
    model.fit(X_scaled, y)
    return model, scaler, features

def forecast_one_month(df, model, scaler, features, lags=[1,2,3]):
    """Forecast the next single month after df's last date."""
    last_date = df['Date'].max()
    next_date = (last_date + pd.offsets.MonthEnd(1))

    new_row = {
        'Date': next_date,
        'Month': next_date.month,
        'R1': df['R1'].iloc[-1],  # substitute future regressors if available
        'R2': df['R2'].iloc[-1],
    }

    for lag in lags:
        new_row[f'lag_{lag}'] = df['resid'].iloc[-lag]

    X_new = pd.DataFrame([new_row])[features]
    X_new_scaled = scaler.transform(X_new)
    pred_resid = model.predict(X_new_scaled)[0]

    # Seasonal adjustment
    month_seasonal = df.groupby('Month')['seasonal'].mean().get(next_date.month, 0)

    # Linear trend extrapolation
    trend_model = LinearRegression()
    X_trend = np.arange(len(df)).reshape(-1,1)
    y_trend = df['trend'].values
    trend_model.fit(X_trend, y_trend)
    future_trend = trend_model.predict([[len(df)+1]])[0]

    forecast_value = pred_resid + month_seasonal + future_trend

    return next_date, forecast_value

# ---------- STEP 2: Walk-forward backtest & tuning ----------

def knn_csd_backtest(df, backtest_horizon=3, neighbor_candidates=range(2,16), lags=[1,2,3]):
    df = preprocess(df)
    df = deseasonalize_and_detrend(df)
    df = add_lag_features(df, 'resid', lags=lags)

    max_index = len(df) - 1
    backtest_results = []

    for k in neighbor_candidates:
        preds = []
        actuals = []
        dates = []

        for i in range(backtest_horizon, 0, -1):
            train_end_idx = max_index - i
            df_train = df.iloc[:train_end_idx+1].copy()

            if len(df_train) < max(lags)+1:
                continue  # not enough data

            model, scaler, features = train_knn_on_resid(df_train, n_neighbors=k, lags=lags)
            forecast_date, forecast_value = forecast_one_month(df_train, model, scaler, features, lags=lags)

            actual_row = df[df['Date'] == forecast_date]
            if actual_row.empty:
                continue

            actual_value = actual_row['Value'].values[0]
            preds.append(forecast_value)
            actuals.append(actual_value)
            dates.append(forecast_date)

            backtest_results.append({
                'Date': forecast_date,
                'Actual': actual_value,
                'Forecast': forecast_value,
                'n_neighbors': k
            })

        # Compute RMSE for this k
        if len(actuals) > 0:
            rmse = mean_squared_error(actuals, preds, squared=False)
        else:
            rmse = np.nan

        backtest_results.append({
            'Date': None,
            'Actual': None,
            'Forecast': None,
            'n_neighbors': k,
            'RMSE': rmse
        })

    results_df = pd.DataFrame(backtest_results)

    # Separate summary RMSE table
    rmse_summary = (
        results_df.dropna(subset=['RMSE'])
        .groupby('n_neighbors', as_index=False)['RMSE']
        .mean()
        .sort_values('RMSE')
    )

    best_k = rmse_summary.iloc[0]['n_neighbors'] if not rmse_summary.empty else None

    return results_df.dropna(subset=['Date']), rmse_summary, best_k

# ---------- STEP 3: Example usage ----------

# df = pd.read_csv("your_timeseries.csv")
# backtest_df, rmse_summary, best_k = knn_csd_backtest(df, backtest_horizon=3, neighbor_candidates=range(2,16))

# print("\nBacktest Predictions:")
# print(backtest_df)

# print("\nRMSE Summary:")
# print(rmse_summary)

# print(f"\nüèÜ Best n_neighbors = {best_k}")
