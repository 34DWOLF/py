import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LinearRegression
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.metrics import mean_squared_error
from joblib import Parallel, delayed
import multiprocessing

# ---------- STEP 1: Helper functions ----------

def preprocess(df):
    df = df.copy()
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date').reset_index(drop=True)
    df['Month'] = df['Date'].dt.month
    return df

def deseasonalize_and_detrend(df, period=12):
    df = df.copy()
    decomposition = seasonal_decompose(df['Value'], period=period, model='additive', extrapolate_trend='freq')
    df['trend'] = decomposition.trend
    df['seasonal'] = decomposition.seasonal
    df['resid'] = df['Value'] - df['trend'] - df['seasonal']
    df['trend'].fillna(method='bfill', inplace=True)
    df['trend'].fillna(method='ffill', inplace=True)
    df['resid'].fillna(0, inplace=True)
    return df

def add_lag_features(df, target_col='resid', lags=[1,2,3]):
    df = df.copy()
    for lag in lags:
        df[f'lag_{lag}'] = df[target_col].shift(lag)
    return df.dropna()

def train_knn_on_resid(df, regressors=['R1','R2'], lags=[1,2,3], n_neighbors=5):
    features = regressors + [f'lag_{l}' for l in lags]
    X = df[features]
    y = df['resid']
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    model = KNeighborsRegressor(n_neighbors=n_neighbors)
    model.fit(X_scaled, y)
    return model, scaler, features

def forecast_one_month(df, model, scaler, features, lags=[1,2,3]):
    last_date = df['Date'].max()
    next_date = (last_date + pd.offsets.MonthEnd(1))

    new_row = {
        'Date': next_date,
        'Month': next_date.month,
        'R1': df['R1'].iloc[-1],
        'R2': df['R2'].iloc[-1],
    }
    for lag in lags:
        new_row[f'lag_{lag}'] = df['resid'].iloc[-lag]

    X_new = pd.DataFrame([new_row])[features]
    X_new_scaled = scaler.transform(X_new)
    pred_resid = model.predict(X_new_scaled)[0]

    month_seasonal = df.groupby('Month')['seasonal'].mean().get(next_date.month, 0)

    trend_model = LinearRegression()
    X_trend = np.arange(len(df)).reshape(-1,1)
    y_trend = df['trend'].values
    trend_model.fit(X_trend, y_trend)
    future_trend = trend_model.predict([[len(df)+1]])[0]

    forecast_value = pred_resid + month_seasonal + future_trend
    return next_date, forecast_value

# ---------- STEP 2: Backtest worker (per neighbor candidate) ----------

def backtest_for_k(df, k, backtest_horizon=3, lags=[1,2,3]):
    max_index = len(df) - 1
    preds, actuals, dates = [], [], []
    backtest_records = []

    for i in range(backtest_horizon, 0, -1):
        train_end_idx = max_index - i
        df_train = df.iloc[:train_end_idx+1].copy()

        if len(df_train) < max(lags)+1:
            continue

        model, scaler, features = train_knn_on_resid(df_train, n_neighbors=k, lags=lags)
        forecast_date, forecast_value = forecast_one_month(df_train, model, scaler, features, lags=lags)

        actual_row = df[df['Date'] == forecast_date]
        if actual_row.empty:
            continue

        actual_value = actual_row['Value'].values[0]
        preds.append(forecast_value)
        actuals.append(actual_value)
        dates.append(forecast_date)

        backtest_records.append({
            'Date': forecast_date,
            'Actual': actual_value,
            'Forecast': forecast_value,
            'n_neighbors': k
        })

    rmse = mean_squared_error(actuals, preds, squared=False) if len(actuals) > 0 else np.nan
    return k, rmse, backtest_records

# ---------- STEP 3: Parallelized backtest & final model ----------

def knn_csd_backtest_parallel(df, backtest_horizon=3, neighbor_candidates=range(2,16), lags=[1,2,3]):
    df = preprocess(df)
    df = deseasonalize_and_detrend(df)
    df = add_lag_features(df, 'resid', lags=lags)

    n_jobs = min(len(neighbor_candidates), multiprocessing.cpu_count())

    results = Parallel(n_jobs=n_jobs)(
        delayed(backtest_for_k)(df, k, backtest_horizon, lags) for k in neighbor_candidates
    )

    # Unpack results
    backtest_dfs = []
    summary_records = []
    for k, rmse, records in results:
        summary_records.append({'n_neighbors': k, 'RMSE': rmse})
        backtest_dfs.extend(records)

    backtest_df = pd.DataFrame(backtest_dfs)
    rmse_summary = pd.DataFrame(summary_records).sort_values('RMSE')

    best_k = rmse_summary.iloc[0]['n_neighbors'] if not rmse_summary.empty else None

    # Train final model on full dataset with best_k
    final_model, final_scaler, final_features = train_knn_on_resid(df, n_neighbors=best_k, lags=lags)

    final_artifacts = {
        'model': final_model,
        'scaler': final_scaler,
        'features': final_features,
        'lags': lags,
        'best_k': best_k,
        'deseasonalized_df': df
    }

    return backtest_df, rmse_summary, final_artifacts

# ---------- STEP 4: Example usage ----------

# df = pd.read_csv("your_timeseries.csv")
# backtest_df, rmse_summary, final_artifacts = knn_csd_backtest_parallel(
#     df,
#     backtest_horizon=6,
#     neighbor_candidates=range(2,21),
#     lags=[1,2,3]
# )

# print("\nüìä Backtest Predictions:")
# print(backtest_df)

# print("\nüìù RMSE Summary:")
# print(rmse_summary)

# print(f"\nüèÜ Best n_neighbors = {final_artifacts['best_k']}")

# You can now use `final_artifacts`['model'] to generate future forecasts.