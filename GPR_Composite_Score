import pandas as pd
import numpy as np
from statsmodels.tsa.arima.model import ARIMA
import re
import warnings
warnings.filterwarnings('ignore')

#######################################################################
# CENTRALIZED PARAMETER SECTION - All parameters defined only once
#######################################################################

# Component weights for the composite GPR score
DEFAULT_WEIGHTS = {
    'current_gpr': 0.3,       # Weight for current GPR
    'historic_gpr': 0.15,     # Weight for historic GPR
    'global_relative': 0.2,   # Weight for GPR relative to rest of world
    'historic_relative': 0.15, # Weight for GPR relative to country's history
    'forecast': 0.2           # Weight for forecasted GPR
}

# Sensitivity parameters
DEFAULT_RECENCY_WEIGHT = 0.7       # Weight given to recent data vs historical (0-1)
DEFAULT_OUTLIER_SENSITIVITY = 1.5   # Multiplier for sensitivity to recent outliers (>1)

# Coverage bias correction parameters
DEFAULT_COVERAGE_BIAS_THRESHOLD = 1.25  # Threshold above average for identifying bias (lower = stricter)
DEFAULT_COVERAGE_ADJUSTMENT_POWER = 2.0  # Power factor for adjustment (higher = stronger)

# Countries to exclude from coverage adjustment (even if they have high coverage)
# This can be useful for countries where high news coverage is justified by actual geopolitical importance
# rather than media bias or for countries where you want to preserve the raw GPR values
DEFAULT_COVERAGE_ADJUSTMENT_EXCLUSIONS = [
    'CHN',  # China
    'HKG',  # Hong Kong
    'MEX'   # Mexico
]

# Forecasting parameters
DEFAULT_FORECAST_WINDOW = 24  # Months of data used for forecasting
DEFAULT_ARIMA_ORDER = (1, 1, 1)  # Order parameters for ARIMA model
DEFAULT_RECENT_TREND_WINDOW = 6  # Months of data used for recent trend calculation

#######################################################################
# COUNTRY CODE TO NAME MAPPING - For consistent country naming
#######################################################################

DEFAULT_COUNTRY_CODE_MAP = {
    'USA': 'United States', 'GBR': 'United Kingdom', 'CHN': 'China', 'RUS': 'Russia',
    'DEU': 'Germany', 'FRA': 'France', 'JPN': 'Japan', 'IND': 'India', 'BRA': 'Brazil',
    'ITA': 'Italy', 'CAN': 'Canada', 'AUS': 'Australia', 'ESP': 'Spain', 'MEX': 'Mexico',
    'KOR': 'South Korea', 'IDN': 'Indonesia', 'TUR': 'Turkey', 'SAU': 'Saudi Arabia',
    'ZAF': 'South Africa', 'ARG': 'Argentina', 'EGY': 'Egypt', 'NLD': 'Netherlands',
    'THA': 'Thailand', 'PHL': 'Philippines', 'PAK': 'Pakistan', 'UKR': 'Ukraine',
    'POL': 'Poland', 'IRN': 'Iran', 'COL': 'Colombia', 'CHE': 'Switzerland',
    'SWE': 'Sweden', 'BEL': 'Belgium', 'NOR': 'Norway', 'VNM': 'Vietnam',
    'TWN': 'Taiwan', 'ISR': 'Israel', 'MYS': 'Malaysia', 'PER': 'Peru',
    'HKG': 'Hong Kong', 'CHL': 'Chile', 'FIN': 'Finland', 'TUN': 'Tunisia',
    'DNK': 'Denmark', 'PRT': 'Portugal', 'HUN': 'Hungary', 'VEN': 'Venezuela'
}

def create_composite_gpr(
        file_path, 
        weights=DEFAULT_WEIGHTS,
        recency_weight=DEFAULT_RECENCY_WEIGHT, 
        outlier_sensitivity=DEFAULT_OUTLIER_SENSITIVITY,
        coverage_bias_threshold=DEFAULT_COVERAGE_BIAS_THRESHOLD, 
        coverage_adjustment_power=DEFAULT_COVERAGE_ADJUSTMENT_POWER,
        coverage_adjustment_exclusions=DEFAULT_COVERAGE_ADJUSTMENT_EXCLUSIONS,
        forecast_window=DEFAULT_FORECAST_WINDOW,
        arima_order=DEFAULT_ARIMA_ORDER,
        recent_trend_window=DEFAULT_RECENT_TREND_WINDOW,
        country_code_map=DEFAULT_COUNTRY_CODE_MAP
    ):
    """
    Create a composite GPR rating using the Dario Caldara and Matteo Iacoviello Geopolitical Risk data.
    Only the Composite GPR is scaled to a 1-10 range; all other metrics retain their original values.
    Enhanced to be more sensitive to recent outliers and account for coverage bias.
    
    Parameters:
    file_path (str): Path to the CSV file containing GPR data
    weights (dict): Dictionary containing weights for each component of the composite score
    recency_weight (float): Weight given to recent data vs historical (0-1, higher = more recent focus)
    outlier_sensitivity (float): Multiplier for sensitivity to recent outliers (>1 = more sensitive)
    coverage_bias_threshold (float): Threshold above average for identifying coverage bias (lower = stricter)
    coverage_adjustment_power (float): Power factor for coverage adjustment (higher = stronger adjustment)
    coverage_adjustment_exclusions (list): List of country codes to exclude from coverage adjustment
    forecast_window (int): Number of months of data to use for forecasting
    arima_order (tuple): Order parameters (p,d,q) for ARIMA forecasting model
    recent_trend_window (int): Number of months to use for recent trend calculation
    country_code_map (dict): Mapping of country codes to full country names
    
    Returns:
    pandas.DataFrame: DataFrame containing the composite GPR scores
    """
    # Ensure weights sum to 1
    weight_sum = sum(weights.values())
    if weight_sum != 1.0:
        # Create a copy to avoid modifying the global DEFAULT_WEIGHTS
        weights = weights.copy()
        for key in weights:
            weights[key] = weights[key] / weight_sum
    
    # Read the data
    df = pd.read_csv(file_path)
    print(f"Data loaded with {len(df)} rows")
    
    # Convert month column to datetime
    df['date'] = pd.to_datetime(df['month'])
    
    # Get all country codes from columns
    current_gpr_cols = [col for col in df.columns if col.startswith('GPRC_')]
    historic_gpr_cols = [col for col in df.columns if col.startswith('GPRHC_')]
    
    # Extract country codes
    country_codes = [col.split('_')[1] for col in current_gpr_cols]
    print(f"Found {len(country_codes)} countries")
    
    # Create mapping of country codes to full country names using var_name and var_label
    country_names = {}
    
    # Update with the default mapping
    country_names.update(country_code_map)
    
    # Create a mapping of var_name to var_label
    var_name_to_label = {}
    
    # Only do this if var_name and var_label columns exist - this will override defaults if found
    if 'var_name' in df.columns and 'var_label' in df.columns:
        for _, row in df.drop_duplicates('var_name').iterrows():
            if isinstance(row['var_name'], str) and isinstance(row['var_label'], str):
                var_name_to_label[row['var_name']] = row['var_label']
                
                # If this is a current GPR country column, extract the country name
                if row['var_name'].startswith('GPRC_'):
                    country_code = row['var_name'].split('_')[1]
                    country_name_match = re.search(r'\((.*?)\)$', row['var_label'])
                    if country_name_match:
                        country_name = country_name_match.group(1)
                        country_names[country_code] = country_name
    
    # If we couldn't extract country names from var_label, use the country codes
    if not country_names:
        for code in country_codes:
            country_names[code] = code
    
    # Get the data for forecasting and recent trend analysis
    recent_dates = sorted(df['date'].unique())[-forecast_window:]
    recent_df = df[df['date'].isin(recent_dates)]
    
    # Get the very recent months for detecting recent outliers
    very_recent_dates = sorted(df['date'].unique())[-recent_trend_window:]
    very_recent_df = df[df['date'].isin(very_recent_dates)]
    
    # Get the latest date with data
    latest_date = recent_df['date'].max()
    latest_df = df[df['date'] == latest_date]
    
    # Calculate global average coverage for normalization
    global_avg_coverage = {}
    for country_code in country_codes:
        current_gpr_col = f'GPRC_{country_code}'
        if current_gpr_col in df.columns:
            global_avg_coverage[country_code] = df[current_gpr_col].mean()
    
    # Find countries with potential coverage bias - using more aggressive threshold
    # Exclude countries in the exclusion list
    overall_avg = np.mean(list(global_avg_coverage.values()))
    coverage_bias_countries = {
        code: val/overall_avg for code, val in global_avg_coverage.items() 
        if val > overall_avg * coverage_bias_threshold and code not in coverage_adjustment_exclusions
    }
    
    # Print identified countries with coverage bias
    bias_countries = sorted([(country_names.get(code, code), bias) 
                            for code, bias in coverage_bias_countries.items()], 
                           key=lambda x: x[1], reverse=True)
    
    print("Countries with coverage bias (bias factor):")
    for country, bias in bias_countries:
        print(f"  {country}: {bias:.2f}x average coverage")
    
    # Print excluded countries that would have been adjusted
    excluded_with_bias = [
        (country_names.get(code, code), global_avg_coverage[code]/overall_avg)
        for code in coverage_adjustment_exclusions
        if code in global_avg_coverage and global_avg_coverage[code] > overall_avg * coverage_bias_threshold
    ]
    if excluded_with_bias:
        print("\nExcluded from adjustment despite high coverage:")
        for country, bias in excluded_with_bias:
            print(f"  {country}: {bias:.2f}x average coverage (excluded)")
    
    # Initialize result dataframe
    result_columns = ['Date', 'Country', 'Composite GPR', 'Current GPR', 'Historic GPR', 
                      'Average GPR over time', 'Average GPR of the rest of the countries', 
                      'Forecasted GPR', 'Recent Trend', 'Coverage Adjustment', 'Raw Bias Factor', 
                      'Adjustment Applied']
    result_df = pd.DataFrame(columns=result_columns)
    
    # Process each country
    for i, country_code in enumerate(country_codes):
        print(f"Processing country {i+1}/{len(country_codes)}: {country_code}")
        
        current_gpr_col = f'GPRC_{country_code}'
        historic_gpr_col = f'GPRHC_{country_code}'
        
        # Get current and historic GPR values for the latest date
        if len(latest_df) > 0:
            latest_row = latest_df.iloc[0]
            current_gpr = latest_row[current_gpr_col]
            historic_gpr = latest_row[historic_gpr_col]
        else:
            print(f"No data for the latest date for {country_code}, skipping")
            continue
        
        # Calculate average GPR over time with stronger weighting for recent data
        if len(recent_df) > 0:
            # Calculate weighted average with exponential decay
            recent_series = recent_df[current_gpr_col].dropna()
            if len(recent_series) > 0:
                weights_exp = np.exp(np.linspace(0, 2, len(recent_series))) * recency_weight
                # Normalize weights to sum to 1
                weights_exp = weights_exp / np.sum(weights_exp)
                # Calculate weighted average
                weighted_avg = np.sum(recent_series.values * weights_exp)
                
                # Calculate standard average for comparison
                std_avg = df[current_gpr_col].mean()
                
                # Use a blend of standard and recency-weighted average
                avg_gpr_over_time = weighted_avg * recency_weight + std_avg * (1 - recency_weight)
            else:
                avg_gpr_over_time = df[current_gpr_col].mean()
        else:
            avg_gpr_over_time = df[current_gpr_col].mean()
        
        # Calculate average GPR of the rest of the countries for the latest date
        other_countries_cols = [col for col in current_gpr_cols if col != current_gpr_col]
        avg_gpr_rest = latest_row[other_countries_cols].mean()
        
        # Calculate recent trend (percentage change in last few months)
        if len(very_recent_df) >= 2:
            earliest_recent = very_recent_df.iloc[0][current_gpr_col]
            latest_recent = very_recent_df.iloc[-1][current_gpr_col]
            if earliest_recent > 0:
                recent_trend = (latest_recent - earliest_recent) / earliest_recent
            else:
                recent_trend = 0
        else:
            recent_trend = 0
        
        # Apply outlier sensitivity to recent trend
        if abs(recent_trend) > 0.1:  # If there's a significant trend
            recent_trend = recent_trend * outlier_sensitivity
        
        # Calculate coverage adjustment factor for countries with heavy news coverage
        # Store raw bias factor for reporting
        raw_bias_factor = 1.0
        coverage_adjustment = 1.0
        adjustment_applied = "No"
        
        if country_code in coverage_bias_countries:
            bias_factor = coverage_bias_countries[country_code]
            raw_bias_factor = bias_factor
            
            # Apply more aggressive adjustment using power factor
            coverage_adjustment = 1.0 / (bias_factor ** coverage_adjustment_power)
            adjustment_applied = "Yes"
        elif country_code in coverage_adjustment_exclusions and country_code in global_avg_coverage:
            # This is an excluded country - show bias factor but don't apply adjustment
            bias = global_avg_coverage[country_code]/overall_avg
            if bias > coverage_bias_threshold:
                raw_bias_factor = bias
                adjustment_applied = "No (Excluded)"
        
        # Forecast the GPR for next month using ARIMA
        try:
            # Get GPR time series for forecasting
            country_gpr_series = recent_df[current_gpr_col].dropna()
            
            if len(country_gpr_series) >= forecast_window/2:  # Need enough data for forecasting
                model = ARIMA(country_gpr_series, order=arima_order)
                model_fit = model.fit()
                forecast = model_fit.forecast(steps=1)[0]
            else:
                # Use simple moving average if not enough data
                forecast = country_gpr_series.rolling(window=min(3, len(country_gpr_series))).mean().iloc[-1]
        except Exception as e:
            print(f"Forecasting error for {country_code}: {e}")
            # Fallback to last value if forecasting fails
            forecast = current_gpr
        
        # Find the global min and max for scaling the composite score
        all_gpr_values = []
        for col in current_gpr_cols + historic_gpr_cols:
            all_gpr_values.extend(df[col].dropna().tolist())
        
        global_min = min(all_gpr_values)
        global_max = max(all_gpr_values)
        
        # For relative position within current global landscape - APPLY COVERAGE ADJUSTMENT HERE TOO
        current_gpr_values = []
        for col in current_gpr_cols:
            val = latest_row[col]
            # Apply coverage adjustment to other countries' values when calculating relative position
            # Skip excluded countries
            col_country_code = col.split('_')[1]
            if col_country_code in coverage_bias_countries:
                col_bias = coverage_bias_countries[col_country_code]
                col_adj = 1.0 / (col_bias ** coverage_adjustment_power)
                val = val * col_adj
            current_gpr_values.append(val)
            
        current_min = min(current_gpr_values)
        current_max = max(current_gpr_values)
        
        # Use adjusted current GPR for relative position calculation
        adjusted_current_gpr = current_gpr * coverage_adjustment
        global_relative_position = (adjusted_current_gpr - current_min) / (current_max - current_min) if current_max > current_min else 0.5
        
        # For relative position compared to country's own history with heightened sensitivity to recent changes
        # Apply coverage adjustment to historical data as well
        country_values = df[current_gpr_col].values
        adjusted_country_values = country_values * coverage_adjustment
        country_min = min(adjusted_country_values)
        country_max = max(adjusted_country_values)
        
        # Enhance historical relative position by factoring in recent trend
        base_historic_relative = (adjusted_current_gpr - country_min) / (country_max - country_min) if country_max > country_min else 0.5
        
        # Adjust historical position based on recent trend
        if recent_trend > 0:
            # Increasing trend should increase the relative position
            historic_relative_position = base_historic_relative * (1 + recent_trend * recency_weight)
            # Cap at 1.0
            historic_relative_position = min(historic_relative_position, 1.0)
        else:
            # Decreasing trend should decrease the relative position
            historic_relative_position = base_historic_relative * (1 + recent_trend * recency_weight)
            # Floor at 0.0
            historic_relative_position = max(historic_relative_position, 0.0)
        
        # Apply coverage adjustment to current_gpr and historic_gpr
        adjusted_current_gpr = current_gpr * coverage_adjustment
        adjusted_historic_gpr = historic_gpr * coverage_adjustment
        
        # Calculate weighted components (using adjusted values)
        weighted_current = weights['current_gpr'] * adjusted_current_gpr
        weighted_historic = weights['historic_gpr'] * adjusted_historic_gpr
        weighted_global_relative = weights['global_relative'] * (adjusted_current_gpr * global_relative_position)
        weighted_historic_relative = weights['historic_relative'] * (adjusted_current_gpr * historic_relative_position)
        weighted_forecast = weights['forecast'] * (forecast * coverage_adjustment)
        
        # Sum the weighted components
        raw_composite_score = weighted_current + weighted_historic + weighted_global_relative + weighted_historic_relative + weighted_forecast
        
        # Scale only the composite score to 1-10 range
        # Find min and max across all potential composite scores for scaling
        all_raw_composites = []
        for j, code in enumerate(country_codes):
            if j != i:  # Skip current country to avoid redundant calculation
                try:
                    c_gpr_col = f'GPRC_{code}'
                    h_gpr_col = f'GPRHC_{code}'
                    
                    if c_gpr_col in latest_row and h_gpr_col in latest_row:
                        c_gpr = latest_row[c_gpr_col]
                        h_gpr = latest_row[h_gpr_col]
                        
                        # Apply coverage adjustment if applicable (skip excluded countries)
                        if code in coverage_bias_countries:
                            c_bias = coverage_bias_countries[code]
                            c_adj = 1.0 / (c_bias ** coverage_adjustment_power)
                            c_gpr = c_gpr * c_adj
                            h_gpr = h_gpr * c_adj
                        
                        # Simple estimation of other countries' composite scores (for scaling purposes only)
                        all_raw_composites.append(weights['current_gpr'] * c_gpr + weights['historic_gpr'] * h_gpr)
                except:
                    pass
        
        all_raw_composites.append(raw_composite_score)
        composite_min = min(all_raw_composites)
        composite_max = max(all_raw_composites)
        
        # Scale to 1-10 range
        scaled_composite = 1 + 9 * (raw_composite_score - composite_min) / (composite_max - composite_min) if composite_max > composite_min else 5.0
        
        # Get full country name from mapping, or use country code if not found
        country_name = country_names.get(country_code, country_code)
        
        # Add to result dataframe
        new_row = {
            'Date': latest_date,
            'Country': country_name,  # Full country name instead of code
            'Composite GPR': round(scaled_composite, 2),  # Only this is scaled to 1-10
            'Current GPR': round(current_gpr, 4),  # Original value
            'Historic GPR': round(historic_gpr, 4),  # Original value
            'Average GPR over time': round(avg_gpr_over_time, 4),  # Original value
            'Average GPR of the rest of the countries': round(avg_gpr_rest, 4),  # Original value
            'Forecasted GPR': round(forecast, 4),  # Original value
            'Recent Trend': round(recent_trend * 100, 2),  # Percentage change
            'Coverage Adjustment': round(coverage_adjustment, 4),  # Adjustment for coverage bias
            'Raw Bias Factor': round(raw_bias_factor, 2),  # Raw bias factor for reference
            'Adjustment Applied': adjustment_applied  # Whether adjustment was applied
        }
        result_df = pd.concat([result_df, pd.DataFrame([new_row])], ignore_index=True)
    
    # Sort by Composite GPR (descending)
    result_df = result_df.sort_values('Composite GPR', ascending=False)
    
    return result_df

def main():
    """
    Main function to run the GPR composite rating calculator.
    Uses centralized default parameters defined at the top of the file.
    """
    # File path to the GPR data
    file_path = ''
    
    # Create composite GPR using the centralized parameters
    # All parameters have defaults defined at the top of the file
    # Any parameter can be overridden here if needed
    result_df = create_composite_gpr(
        file_path=file_path,
        # All other parameters use defaults unless explicitly specified here
        
        # Example of overriding default parameters:
        # coverage_adjustment_exclusions=['USA', 'CHN', 'HKG']  # Add USA to exclusion list
    )
    
    # Display results
    print(f"Composite GPR Ratings (weights: {DEFAULT_WEIGHTS})")
    print(f"Total countries analyzed: {len(result_df)}")
    display(result_df)
    
    # Return the result dataframe (though it's not saved as per requirements)
    return result_df

if __name__ == "__main__":
    main()
