import pandas as pd
import requests
import json
import spacy
from spacy.training import Example
from spacy.util import minibatch, compounding
import random
import re
import warnings
warnings.filterwarnings('ignore')

def fetch_mitre_attack_data():
    """
    Fetch MITRE ATT&CK data from GitHub
    """
    print("Fetching MITRE ATT&CK data...")
    
    # MITRE ATT&CK STIX data URL
    url = "https://raw.githubusercontent.com/mitre/cti/master/enterprise-attack/enterprise-attack.json"
    
    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        
        # Extract threat actors (intrusion-sets)
        threat_actors = []
        for obj in data['objects']:
            if obj['type'] == 'intrusion-set':
                actor_info = {
                    'Name': obj.get('name', ''),
                    'Description': obj.get('description', ''),
                    'Aliases': obj.get('aliases', []),
                    'Created': obj.get('created', ''),
                    'Modified': obj.get('modified', '')
                }
                threat_actors.append(actor_info)
        
        mitre_df = pd.DataFrame(threat_actors)
        print(f"Successfully fetched {len(mitre_df)} threat actors from MITRE ATT&CK")
        return mitre_df
    
    except Exception as e:
        print(f"Error fetching MITRE data: {e}")
        return pd.DataFrame()

def create_spacy_ner_model(df_spacy_train):
    """
    Create and train a spaCy NER model for nation state extraction
    """
    print("\nCreating spaCy NER model...")
    
    # Create blank English model
    nlp = spacy.blank("en")
    
    # Add NER component
    if "ner" not in nlp.pipe_names:
        ner = nlp.add_pipe("ner")
    else:
        ner = nlp.get_pipe("ner")
    
    # Add label for nation states
    ner.add_label("NATION_STATE")
    
    # Convert df_spacy_train to training format
    print(f"Processing {len(df_spacy_train)} training examples from SQL data...")
    training_data = []
    
    for _, row in df_spacy_train.iterrows():
        text = str(row.get('Description', ''))
        country = str(row.get('Suspect', ''))
        
        if not text or not country:
            continue
            
        # Find all occurrences of the country and its variations in the text
        entities = []
        
        # Country name variations
        country_variations = {
            'Russia': ['Russia', 'Russian', 'Russian Federation', 'USSR', 'Soviet'],
            'China': ['China', 'Chinese', 'PRC', "People's Republic of China"],
            'Iran': ['Iran', 'Iranian', 'Persia', 'Persian'],
            'North Korea': ['North Korea', 'North Korean', 'DPRK'],
            'United States': ['United States', 'American', 'USA', 'US', 'U.S.'],
            'Israel': ['Israel', 'Israeli'],
            'India': ['India', 'Indian'],
            'Pakistan': ['Pakistan', 'Pakistani'],
            'Vietnam': ['Vietnam', 'Vietnamese'],
            'Lebanon': ['Lebanon', 'Lebanese'],
            'South Korea': ['South Korea', 'South Korean', 'ROK', 'Republic of Korea'],
            'United Kingdom': ['United Kingdom', 'UK', 'British', 'Britain'],
            'Ukraine': ['Ukraine', 'Ukrainian'],
            'Belarus': ['Belarus', 'Belarusian'],
        }
        
        # Get variations for this country
        variations = country_variations.get(country, [country])
        
        # Find each variation in the text
        for variation in variations:
            # Case insensitive search
            for match in re.finditer(re.escape(variation), text, re.IGNORECASE):
                start_idx = match.start()
                end_idx = match.end()
                entities.append((start_idx, end_idx, "NATION_STATE"))
        
        if entities:
            # Remove duplicates and overlapping entities
            entities = list(set(entities))
            entities.sort(key=lambda x: x[0])
            
            # Remove overlapping entities
            filtered_entities = []
            last_end = -1
            for start, end, label in entities:
                if start >= last_end:
                    filtered_entities.append((start, end, label))
                    last_end = end
            
            training_data.append((text, {"entities": filtered_entities}))
    
    if not training_data:
        raise ValueError("No valid training data found. Please ensure df_spacy_train contains valid data.")
    
    print(f"Created {len(training_data)} training examples with entities")
    
    # Convert to Example objects
    examples = []
    for text, annotations in training_data:
        doc = nlp.make_doc(text)
        example = Example.from_dict(doc, annotations)
        examples.append(example)
    
    # Train the model
    nlp.begin_training()
    print("Training spaCy model...")
    for i in range(30):
        random.shuffle(examples)
        losses = {}
        for batch in minibatch(examples, size=compounding(4., 32., 1.001)):
            nlp.update(batch, losses=losses)
        if i % 10 == 0:
            print(f"  Iteration {i}, Loss: {losses.get('ner', 0):.2f}")
    
    print("SpaCy model trained successfully")
    return nlp

def extract_nation_states_with_spacy(mitre_df, nlp):
    """
    Extract nation states from MITRE descriptions using trained spaCy NER model
    """
    print("\nExtracting nation states from MITRE descriptions using spaCy...")
    
    # Create a copy to store results
    result_df = mitre_df.copy()
    result_df['primary_nation_state'] = ''
    result_df['match_source'] = ''
    
    extracted_count = 0
    
    for idx, row in result_df.iterrows():
        # Combine name, description and aliases for context
        name = row['Name']
        description = row['Description']
        aliases = row['Aliases']
        
        # Create text for analysis
        text_parts = []
        if name:
            text_parts.append(str(name))
        if description:
            text_parts.append(str(description))
        if isinstance(aliases, list) and aliases:
            text_parts.extend([str(alias) for alias in aliases])
        
        combined_text = ' '.join(text_parts)
        
        # Process with spaCy
        doc = nlp(combined_text)
        nation_states = []
        
        for ent in doc.ents:
            if ent.label_ == "NATION_STATE":
                nation_states.append(ent.text)
        
        if nation_states:
            # Normalize the extracted nation state
            nation_text = nation_states[0]  # Take the first one
            
            # Map variations to standard names
            nation_mapping = {
                'russian': 'Russia', 'russia': 'Russia', 'russian federation': 'Russia',
                'chinese': 'China', 'china': 'China', 'prc': 'China',
                'iranian': 'Iran', 'iran': 'Iran', 'persia': 'Iran',
                'north korean': 'North Korea', 'north korea': 'North Korea', 'dprk': 'North Korea',
                'american': 'United States', 'united states': 'United States', 'usa': 'United States',
                'israeli': 'Israel', 'israel': 'Israel',
                'indian': 'India', 'india': 'India',
                'pakistani': 'Pakistan', 'pakistan': 'Pakistan',
                'vietnamese': 'Vietnam', 'vietnam': 'Vietnam',
                'lebanese': 'Lebanon', 'lebanon': 'Lebanon',
                'south korean': 'South Korea', 'south korea': 'South Korea',
                'ukrainian': 'Ukraine', 'ukraine': 'Ukraine',
                'belarusian': 'Belarus', 'belarus': 'Belarus',
                'british': 'United Kingdom', 'united kingdom': 'United Kingdom', 'uk': 'United Kingdom',
            }
            
            nation_lower = nation_text.lower()
            nation = nation_mapping.get(nation_lower, nation_text)
            
            result_df.at[idx, 'primary_nation_state'] = nation
            result_df.at[idx, 'match_source'] = 'spacy_extraction'
            extracted_count += 1
    
    print(f"Extracted nation states for {extracted_count} entries using spaCy")
    return result_df

def match_threat_actors(result_df, raw_df):
    """
    Match MITRE threat actors with raw_df based on threat actor names
    Only processes entries that don't already have a nation state
    """
    print("\nMatching remaining threat actors with raw_df...")
    
    # Normalize names for better matching
    def normalize_name(name):
        if pd.isna(name):
            return ''
        # Remove special characters and extra spaces
        name = str(name).strip().lower()
        name = re.sub(r'[^\w\s-]', '', name)
        return name
    
    # Create normalized columns for matching
    result_df['name_normalized'] = result_df['Name'].apply(normalize_name)
    raw_df['threat_actor_normalized'] = raw_df['Threat actor name'].apply(normalize_name)
    
    # Only process entries without nation states
    no_nation_mask = result_df['primary_nation_state'] == ''
    matched_count = 0
    
    for idx in result_df[no_nation_mask].index:
        mitre_name = result_df.at[idx, 'name_normalized']
        
        # Check direct match
        match = raw_df[raw_df['threat_actor_normalized'] == mitre_name]
        if not match.empty:
            nation = match.iloc[0]['primary_nation_state']
            if pd.notna(nation) and nation.strip():
                result_df.at[idx, 'primary_nation_state'] = nation
                result_df.at[idx, 'match_source'] = 'threat_actors_exact'
                matched_count += 1
                continue
        
        # Check if MITRE name is in raw_df threat actor name (partial match)
        for _, raw_row in raw_df.iterrows():
            if mitre_name and (mitre_name in raw_row['threat_actor_normalized'] or \
               raw_row['threat_actor_normalized'] in mitre_name):
                nation = raw_row['primary_nation_state']
                if pd.notna(nation) and nation.strip():
                    result_df.at[idx, 'primary_nation_state'] = nation
                    result_df.at[idx, 'match_source'] = 'threat_actors_partial'
                    matched_count += 1
                    break
        
        # Check aliases
        if result_df.at[idx, 'primary_nation_state'] == '':
            aliases = result_df.at[idx, 'Aliases']
            if isinstance(aliases, list):
                for alias in aliases:
                    alias_normalized = normalize_name(alias)
                    match = raw_df[raw_df['threat_actor_normalized'] == alias_normalized]
                    if not match.empty:
                        nation = match.iloc[0]['primary_nation_state']
                        if pd.notna(nation) and nation.strip():
                            result_df.at[idx, 'primary_nation_state'] = nation
                            result_df.at[idx, 'match_source'] = 'threat_actors_alias'
                            matched_count += 1
                            break
    
    # Clean up temporary columns
    result_df = result_df.drop(['name_normalized'], axis=1)
    
    print(f"Matched {matched_count} additional threat actors from raw_df")
    
    return result_df

def main(raw_df, df_spacy_train):
    """
    Main function to orchestrate the entire process
    Requires df_spacy_train with columns: 'Description' and 'Suspect'
    """
    print("Starting MITRE ATT&CK threat actor matching process...")
    
    # Step 1: Fetch MITRE ATT&CK data
    mitre_df = fetch_mitre_attack_data()
    if mitre_df.empty:
        print("Failed to fetch MITRE data. Exiting.")
        return pd.DataFrame()
    
    # Step 2: Train spaCy model with provided training data
    try:
        nlp = create_spacy_ner_model(df_spacy_train)
    except ValueError as e:
        print(f"Error: {e}")
        return pd.DataFrame()
    
    # Step 3: Extract nation states from MITRE descriptions using spaCy
    result_df = extract_nation_states_with_spacy(mitre_df, nlp)
    
    # Step 4: Match remaining actors with raw_df
    final_df = match_threat_actors(result_df, raw_df)
    
    # Summary statistics
    print("\n=== Summary ===")
    print(f"Total threat actors: {len(final_df)}")
    print(f"Matched nation states: {(final_df['primary_nation_state'] != '').sum()}")
    print(f"Blank nation states: {(final_df['primary_nation_state'] == '').sum()}")
    
    # Print breakdown by source
    print("\n=== Match Source Breakdown ===")
    source_counts = final_df['match_source'].value_counts()
    for source, count in source_counts.items():
        if source:
            print(f"{source}: {count}")
    
    # Print all results with full details
    print("\n=== Full Results ===")
    # Prepare display dataframe
    display_df = final_df[['Name', 'primary_nation_state', 'match_source', 'Description']].copy()
    display_df['primary_nation_state'] = display_df['primary_nation_state'].fillna('')
    display_df['match_source'] = display_df['match_source'].fillna('')
    
    # Truncate description for display
    display_df['Description'] = display_df['Description'].apply(
        lambda x: (str(x)[:100] + '...') if pd.notna(x) and len(str(x)) > 100 else str(x)
    )
    
    # Set pandas display options for better output
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', None)
    pd.set_option('display.max_colwidth', None)
    
    print(display_df.to_string(index=False))
    
    # Reset display options
    pd.reset_option('display.max_rows')
    pd.reset_option('display.max_columns')
    pd.reset_option('display.width')
    pd.reset_option('display.max_colwidth')
    
    return final_df

# Execute the MITRE ATT&CK threat actor matching
if __name__ == "__main__":
    # Load training data from SQL
    # df_spacy_train = pd.read_sql(
    #     'SELECT "Description", "Suspect" FROM threat_actor_training',
    #     connection
    # )
    
    # For testing, use sample training data
    df_spacy_train = pd.DataFrame({
        'Description': [
            'APT28 is a threat group that has been attributed to Russia\'s General Staff Main Intelligence Directorate',
            'Lazarus Group is a North Korean state-sponsored cyber threat group',
            'APT1 is a Chinese cyber espionage group',
            'Indrik Spider is a Russia-based cybercriminal group',
        ],
        'Suspect': [
            'Russia',
            'North Korea',
            'China',
            'Russia'
        ]
    })
    
    # Run the main function with required training data
    result_df = main(raw_df, df_spacy_train)
