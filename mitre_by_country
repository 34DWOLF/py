import pandas as pd
import requests
import json
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from torch.utils.data import Dataset
import numpy as np
import re
import warnings
warnings.filterwarnings('ignore')

# Check if GPU is available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class ThreatActorDataset(Dataset):
    """Dataset for BERT classification"""
    def __init__(self, texts, labels, tokenizer, max_length=256):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
        
        # Create label to id mapping
        unique_labels = sorted(list(set(labels)))
        self.label2id = {label: i for i, label in enumerate(unique_labels)}
        self.id2label = {i: label for label, i in self.label2id.items()}
        
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = self.texts[idx]
        label = self.labels[idx]
        
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(self.label2id[label], dtype=torch.long)
        }

def fetch_mitre_attack_data():
    """
    Fetch MITRE ATT&CK data from GitHub
    """
    print("Fetching MITRE ATT&CK data...")
    
    url = "https://raw.githubusercontent.com/mitre/cti/master/enterprise-attack/enterprise-attack.json"
    
    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        
        threat_actors = []
        for obj in data['objects']:
            if obj['type'] == 'intrusion-set':
                actor_info = {
                    'Name': obj.get('name', ''),
                    'Description': obj.get('description', ''),
                    'Aliases': obj.get('aliases', []),
                    'Created': obj.get('created', ''),
                    'Modified': obj.get('modified', '')
                }
                threat_actors.append(actor_info)
        
        mitre_df = pd.DataFrame(threat_actors)
        print(f"Successfully fetched {len(mitre_df)} threat actors from MITRE ATT&CK")
        return mitre_df
    
    except Exception as e:
        print(f"Error fetching MITRE data: {e}")
        return pd.DataFrame()

def create_bert_classifier(df_train):
    """
    Create and train a BERT classifier for nation state identification
    """
    print("\nCreating BERT classifier...")
    
    # Filter valid training data
    df_train = df_train[df_train['Description'].notna() & df_train['Suspect'].notna()]
    df_train = df_train[df_train['Suspect'].str.strip() != '']
    
    if len(df_train) == 0:
        raise ValueError("No valid training data found.")
    
    # Prepare data
    texts = df_train['Description'].tolist()
    labels = df_train['Suspect'].tolist()
    
    # Get unique labels
    unique_labels = sorted(list(set(labels)))
    label2id = {label: i for i, label in enumerate(unique_labels)}
    id2label = {i: label for label, i in label2id.items()}
    
    print(f"Training on {len(texts)} examples with {len(unique_labels)} nation states")
    
    # Load BERT model and tokenizer
    model_name = "bert-base-uncased"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    
    model = AutoModelForSequenceClassification.from_pretrained(
        model_name,
        num_labels=len(unique_labels),
        label2id=label2id,
        id2label=id2label
    ).to(device)
    
    # Create dataset
    dataset = ThreatActorDataset(texts, labels, tokenizer)
    
    # Training arguments
    training_args = TrainingArguments(
        output_dir="./bert_classifier",
        num_train_epochs=5,
        per_device_train_batch_size=8,
        warmup_steps=100,
        logging_steps=50,
        save_strategy="no",
        evaluation_strategy="no",
        report_to="none",
        fp16=torch.cuda.is_available(),
    )
    
    # Create trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=dataset,
    )
    
    # Train
    print("Training BERT classifier...")
    trainer.train()
    
    print("BERT classifier trained successfully")
    return model, tokenizer, dataset.label2id, dataset.id2label

def extract_nation_states_with_bert(mitre_df, model, tokenizer, label2id, id2label):
    """
    Extract nation states using BERT classifier
    """
    print("\nExtracting nation states from MITRE descriptions using BERT...")
    
    result_df = mitre_df.copy()
    result_df['primary_nation_state'] = ''
    result_df['match_source'] = ''
    result_df['confidence'] = 0.0
    
    model.eval()
    extracted_count = 0
    
    for idx, row in result_df.iterrows():
        # Prepare text
        description = row['Description']
        name = row['Name']
        aliases = row['Aliases']
        
        if not description:
            continue
            
        # Use description as primary text
        text = str(description)
        
        # Tokenize
        inputs = tokenizer(
            text,
            truncation=True,
            max_length=256,
            padding='max_length',
            return_tensors='pt'
        ).to(device)
        
        # Predict
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            probabilities = torch.nn.functional.softmax(logits, dim=-1)
            confidence, predicted_id = torch.max(probabilities, dim=-1)
            
        # Get nation
        predicted_nation = id2label[predicted_id.item()]
        confidence_score = confidence.item()
        
        # Only accept predictions with reasonable confidence
        if confidence_score > 0.3:
            result_df.at[idx, 'primary_nation_state'] = predicted_nation
            result_df.at[idx, 'match_source'] = 'bert_extraction'
            result_df.at[idx, 'confidence'] = confidence_score
            extracted_count += 1
    
    print(f"Extracted nation states for {extracted_count} entries using BERT")
    return result_df

def match_threat_actors(result_df, raw_df):
    """
    Match MITRE threat actors with raw_df for remaining entries
    """
    print("\nMatching remaining threat actors with raw_df...")
    
    def normalize_name(name):
        if pd.isna(name):
            return ''
        name = str(name).strip().lower()
        name = re.sub(r'[^\w\s-]', '', name)
        return name
    
    result_df['name_normalized'] = result_df['Name'].apply(normalize_name)
    raw_df['threat_actor_normalized'] = raw_df['Threat actor name'].apply(normalize_name)
    
    no_nation_mask = result_df['primary_nation_state'] == ''
    matched_count = 0
    
    for idx in result_df[no_nation_mask].index:
        mitre_name = result_df.at[idx, 'name_normalized']
        
        # Exact match
        match = raw_df[raw_df['threat_actor_normalized'] == mitre_name]
        if not match.empty:
            nation = match.iloc[0]['primary_nation_state']
            if pd.notna(nation) and nation.strip():
                result_df.at[idx, 'primary_nation_state'] = nation
                result_df.at[idx, 'match_source'] = 'threat_actors_exact'
                result_df.at[idx, 'confidence'] = 1.0
                matched_count += 1
                continue
        
        # Partial match
        for _, raw_row in raw_df.iterrows():
            if mitre_name and (mitre_name in raw_row['threat_actor_normalized'] or 
                             raw_row['threat_actor_normalized'] in mitre_name):
                nation = raw_row['primary_nation_state']
                if pd.notna(nation) and nation.strip():
                    result_df.at[idx, 'primary_nation_state'] = nation
                    result_df.at[idx, 'match_source'] = 'threat_actors_partial'
                    result_df.at[idx, 'confidence'] = 0.8
                    matched_count += 1
                    break
        
        # Alias match
        if result_df.at[idx, 'primary_nation_state'] == '':
            aliases = result_df.at[idx, 'Aliases']
            if isinstance(aliases, list):
                for alias in aliases:
                    alias_normalized = normalize_name(alias)
                    match = raw_df[raw_df['threat_actor_normalized'] == alias_normalized]
                    if not match.empty:
                        nation = match.iloc[0]['primary_nation_state']
                        if pd.notna(nation) and nation.strip():
                            result_df.at[idx, 'primary_nation_state'] = nation
                            result_df.at[idx, 'match_source'] = 'threat_actors_alias'
                            result_df.at[idx, 'confidence'] = 0.9
                            matched_count += 1
                            break
    
    result_df = result_df.drop(['name_normalized'], axis=1)
    print(f"Matched {matched_count} additional threat actors from raw_df")
    
    return result_df

def main(raw_df, df_train):
    """
    Main function - requires df_train with columns: 'Description' and 'Suspect'
    """
    print("Starting MITRE ATT&CK threat actor matching process with BERT...")
    
    # Step 1: Fetch MITRE data
    mitre_df = fetch_mitre_attack_data()
    if mitre_df.empty:
        print("Failed to fetch MITRE data.")
        return pd.DataFrame()
    
    # Step 2: Train BERT classifier
    try:
        model, tokenizer, label2id, id2label = create_bert_classifier(df_train)
    except Exception as e:
        print(f"Error training BERT: {e}")
        return pd.DataFrame()
    
    # Step 3: Extract nation states using BERT
    result_df = extract_nation_states_with_bert(mitre_df, model, tokenizer, label2id, id2label)
    
    # Step 4: Match remaining with raw_df
    final_df = match_threat_actors(result_df, raw_df)
    
    # Summary
    print("\n=== Summary ===")
    print(f"Total threat actors: {len(final_df)}")
    print(f"Matched nation states: {(final_df['primary_nation_state'] != '').sum()}")
    print(f"Blank nation states: {(final_df['primary_nation_state'] == '').sum()}")
    
    print("\n=== Match Source Breakdown ===")
    source_counts = final_df['match_source'].value_counts()
    for source, count in source_counts.items():
        if source:
            print(f"{source}: {count}")
    
    # Confidence stats
    bert_matches = final_df[final_df['match_source'] == 'bert_extraction']
    if len(bert_matches) > 0:
        print(f"\nBERT Confidence Stats:")
        print(f"  Mean: {bert_matches['confidence'].mean():.3f}")
        print(f"  Min:  {bert_matches['confidence'].min():.3f}")
        print(f"  Max:  {bert_matches['confidence'].max():.3f}")
    
    # Print results
    print("\n=== Full Results ===")
    display_df = final_df[['Name', 'primary_nation_state', 'match_source', 'Description']].copy()
    display_df['primary_nation_state'] = display_df['primary_nation_state'].fillna('')
    display_df['match_source'] = display_df['match_source'].fillna('')
    display_df['Description'] = display_df['Description'].apply(
        lambda x: (str(x)[:100] + '...') if pd.notna(x) and len(str(x)) > 100 else str(x)
    )
    
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', None)
    pd.set_option('display.max_colwidth', None)
    
    print(display_df.to_string(index=False))
    
    pd.reset_option('display.max_rows')
    pd.reset_option('display.max_columns')
    pd.reset_option('display.width')
    pd.reset_option('display.max_colwidth')
    
    # Remove confidence column before returning
    final_df = final_df.drop(['confidence'], axis=1)
    return final_df

# Execute
if __name__ == "__main__":
    # Sample training data
    df_train = pd.DataFrame({
        'Description': [
            'APT28 is a threat group that has been attributed to Russia\'s General Staff Main Intelligence Directorate',
            'Lazarus Group is a North Korean state-sponsored cyber threat group',
            'APT1 is a Chinese cyber espionage group',
            'Indrik Spider is a Russia-based cybercriminal group',
            'Charming Kitten is an Iranian cyber espionage group',
            'Equation Group is tied to United States intelligence',
        ],
        'Suspect': [
            'Russia',
            'North Korea',
            'China',
            'Russia',
            'Iran',
            'United States'
        ]
    })
    
    # Run with BERT
    result_df = main(raw_df, df_train)
