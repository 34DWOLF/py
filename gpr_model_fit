import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.stattools import adfuller
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from itertools import product
import sqlalchemy
import re
import warnings
warnings.filterwarnings('ignore')

def get_data_from_sql(connection_string, query):
    """
    Retrieve GPR data from a SQL database.
    
    Parameters:
    -----------
    connection_string : str
        SQLAlchemy connection string to connect to the database
    query : str
        SQL query to retrieve the data
        
    Returns:
    --------
    pandas.DataFrame
        DataFrame containing the retrieved data
    """
    try:
        # Create SQLAlchemy engine
        engine = sqlalchemy.create_engine(connection_string)
        
        # Read data into DataFrame
        df = pd.read_sql(query, engine)
        
        print(f"Data loaded from SQL with {len(df)} rows")
        return df
    
    except Exception as e:
        print(f"Error connecting to database: {str(e)}")
        raise

def evaluate_forecast_models(df, country_codes=None, test_size=12):
    """
    Evaluate multiple forecasting models for GPR data and find the best model
    based on highest R² values for each country.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        DataFrame containing the GPR data from SQL
    country_codes : list, optional
        List of country codes to evaluate (if None, evaluate all countries)
    test_size : int, optional
        Number of months to use for testing (default: 12 months)
        
    Returns:
    --------
    pandas.DataFrame
        DataFrame containing the best model for each country
    """
    # Convert month column to datetime if needed
    if 'month' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['month']):
        df['date'] = pd.to_datetime(df['month'])
    elif 'date' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['date']):
        df['date'] = pd.to_datetime(df['date'])
    elif 'month' in df.columns:
        df['date'] = df['month']
    
    # Get all country codes from columns if not provided
    if country_codes is None:
        current_gpr_cols = [col for col in df.columns if col.startswith('GPRC_')]
        country_codes = [col.split('_')[1] for col in current_gpr_cols]
    
    print(f"Evaluating forecast models for {len(country_codes)} countries")
    
    # Create a mapping of country codes to country names
    country_names = {}
    if 'var_name' in df.columns and 'var_label' in df.columns:
        for _, row in df.drop_duplicates('var_name').iterrows():
            if isinstance(row['var_name'], str) and isinstance(row['var_label'], str):
                if row['var_name'].startswith('GPRC_'):
                    country_code = row['var_name'].split('_')[1]
                    country_name_match = re.search(r'\((.*?)\)$', row['var_label'])
                    if country_name_match:
                        country_name = country_name_match.group(1)
                        country_names[country_code] = country_name
    
    # Sort data by date
    df = df.sort_values('date')
    
    # Define models to evaluate
    models = {
        'ARIMA(1,1,1)': lambda ts: ARIMA(ts, order=(1, 1, 1)),
        'ARIMA(2,1,2)': lambda ts: ARIMA(ts, order=(2, 1, 2)),
        'ARIMA(3,1,3)': lambda ts: ARIMA(ts, order=(3, 1, 3)),
        'ARIMA(2,1,0)': lambda ts: ARIMA(ts, order=(2, 1, 0)),  # AR only
        'ARIMA(0,1,2)': lambda ts: ARIMA(ts, order=(0, 1, 2)),  # MA only
        'SARIMA(1,1,1)(1,0,1,12)': lambda ts: SARIMAX(ts, order=(1, 1, 1), seasonal_order=(1, 0, 1, 12)),
        'SARIMA(2,1,2)(1,0,1,12)': lambda ts: SARIMAX(ts, order=(2, 1, 2), seasonal_order=(1, 0, 1, 12)),
        'Holt-Winters': lambda ts: ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=12),
        'Simple MA(3)': lambda ts: None,  # Special case handled separately
        'Simple MA(6)': lambda ts: None,  # Special case handled separately
        'Simple MA(12)': lambda ts: None,  # Special case handled separately
    }
    
    # Initialize results DataFrame
    results = []
    
    # Evaluate each country
    for i, country_code in enumerate(country_codes):
        print(f"Processing country {i+1}/{len(country_codes)}: {country_code}")
        
        # Get the GPR column for this country
        gpr_col = f'GPRC_{country_code}'
        
        # Skip if the column doesn't exist
        if gpr_col not in df.columns:
            print(f"Column {gpr_col} not found, skipping")
            continue
        
        # Get the GPR time series
        ts = df[gpr_col].dropna()
        
        # Skip if not enough data
        if len(ts) < test_size + 24:  # Need at least 24 months for training + test_size for testing
            print(f"Not enough data for {country_code}, skipping")
            continue
        
        # Split into train and test sets
        train = ts.iloc[:-test_size]
        test = ts.iloc[-test_size:]
        
        # Initialize metrics for each model
        model_metrics = {}
        
        # Test each model
        for model_name, model_func in models.items():
            try:
                if model_name.startswith('Simple MA'):
                    # Extract window size from model name
                    window = int(model_name.split('(')[1].split(')')[0])
                    
                    # Generate forecast using simple moving average
                    forecast = []
                    for i in range(len(test)):
                        # Get the window of data ending at the last known point
                        if i == 0:
                            window_data = train.iloc[-window:]
                        else:
                            # Combine known train data with the forecasts we've already made
                            window_data = pd.concat([train.iloc[-(window-i):], pd.Series(forecast[:i])])
                        
                        # Calculate the moving average
                        forecast.append(window_data.mean())
                else:
                    # Fit the model
                    model = model_func(train)
                    if isinstance(model, (ARIMA, SARIMAX)):
                        fitted = model.fit()
                        # Generate forecast
                        forecast = fitted.forecast(steps=len(test))
                    else:  # Holt-Winters
                        fitted = model.fit()
                        # Generate forecast
                        forecast = fitted.forecast(len(test))
                
                # Calculate metrics
                r2 = r2_score(test, forecast)
                mse = mean_squared_error(test, forecast)
                mae = mean_absolute_error(test, forecast)
                rmse = np.sqrt(mse)
                
                model_metrics[model_name] = {
                    'R2': r2,
                    'MSE': mse,
                    'MAE': mae,
                    'RMSE': rmse
                }
                
                print(f"  {model_name}: R² = {r2:.4f}, RMSE = {rmse:.4f}")
            
            except Exception as e:
                print(f"  Error with {model_name} for {country_code}: {str(e)}")
        
        # Find the best model based on highest R²
        if model_metrics:
            best_model = max(model_metrics.items(), key=lambda x: x[1]['R2'])
            
            results.append({
                'Country Code': country_code,
                'Country Name': country_names.get(country_code, country_code),
                'Best Model': best_model[0],
                'R2': best_model[1]['R2'],
                'MSE': best_model[1]['MSE'],
                'MAE': best_model[1]['MAE'],
                'RMSE': best_model[1]['RMSE'],
                'All Models': model_metrics
            })
    
    # Convert results to DataFrame
    results_df = pd.DataFrame(results)
    
    # Sort by highest R² (best fit)
    results_df = results_df.sort_values('R2', ascending=False)
    
    return results_df

def find_best_overall_model(results_df):
    """
    Analyzes the results to find the forecasting model with the 
    highest average R² across all countries.
    
    Parameters:
    -----------
    results_df : pandas.DataFrame
        DataFrame with model evaluation results
        
    Returns:
    --------
    pandas.DataFrame
        DataFrame with average R² for each model type
    """
    # Calculate average R² by model type
    model_performance = {}
    
    for _, row in results_df.iterrows():
        all_models = row['All Models']
        for model_name, metrics in all_models.items():
            if model_name not in model_performance:
                model_performance[model_name] = {
                    'R2_sum': 0, 
                    'R2_values': [], 
                    'count': 0
                }
            
            model_performance[model_name]['R2_sum'] += metrics['R2']
            model_performance[model_name]['R2_values'].append(metrics['R2'])
            model_performance[model_name]['count'] += 1
    
    # Calculate average R² and other stats for each model
    for model_name in model_performance:
        r2_values = model_performance[model_name]['R2_values']
        model_performance[model_name].update({
            'Average_R2': model_performance[model_name]['R2_sum'] / model_performance[model_name]['count'],
            'Median_R2': np.median(r2_values),
            'Max_R2': np.max(r2_values),
            'Min_R2': np.min(r2_values),
            'Std_R2': np.std(r2_values)
        })
    
    # Convert to DataFrame and sort by average R² (highest first)
    model_avg_df = pd.DataFrame([
        {
            'Model': model_name, 
            'Average R2': stats['Average_R2'], 
            'Median R2': stats['Median_R2'],
            'Max R2': stats['Max_R2'],
            'Min R2': stats['Min_R2'],
            'Std Dev R2': stats['Std_R2'],
            'Count': stats['count']
        }
        for model_name, stats in model_performance.items()
    ])
    
    model_avg_df = model_avg_df.sort_values('Average R2', ascending=False)
    
    return model_avg_df

def generate_forecast_visualizations(df, country_code, test_size=12):
    """
    Generate visualizations of actual vs. forecasted GPR values
    using different models for a specific country.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        DataFrame containing the GPR data from SQL
    country_code : str
        Country code to analyze
    test_size : int, optional
        Number of months to use for testing
    """
    # Sort data by date
    df = df.sort_values('date')
    
    # Get the GPR column for this country
    gpr_col = f'GPRC_{country_code}'
    
    # Get the GPR time series
    ts = df[gpr_col].dropna()
    
    # Split into train and test sets
    train = ts.iloc[:-test_size]
    test = ts.iloc[-test_size:]
    test_dates = df['date'].iloc[-test_size:]
    
    # Define models to test
    models = {
        'ARIMA(1,1,1)': ARIMA(train, order=(1, 1, 1)),
        'ARIMA(2,1,2)': ARIMA(train, order=(2, 1, 2)),
        'SARIMA(1,1,1)(1,0,1,12)': SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 0, 1, 12)),
        'Holt-Winters': ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=12)
    }
    
    # Create a figure
    plt.figure(figsize=(12, 8))
    
    # Plot actual values
    plt.plot(test_dates, test, 'k-', label='Actual')
    
    # Plot forecasts for each model
    for model_name, model in models.items():
        try:
            if isinstance(model, (ARIMA, SARIMAX)):
                fitted = model.fit()
                # Generate forecast
                forecast = fitted.forecast(steps=len(test))
            else:  # Holt-Winters
                fitted = model.fit()
                # Generate forecast
                forecast = fitted.forecast(len(test))
            
            # Calculate R²
            r2 = r2_score(test, forecast)
            
            # Plot forecast
            plt.plot(test_dates, forecast, '--', label=f'{model_name} (R² = {r2:.4f})')
        
        except Exception as e:
            print(f"Error with {model_name} for {country_code}: {str(e)}")
    
    # Add labels and title
    plt.xlabel('Date')
    plt.ylabel('GPR')
    plt.title(f'Forecasting Models Comparison for {country_code}')
    plt.legend()
    plt.grid(True)
    
    # Show the plot
    plt.tight_layout()
    plt.show()

def update_composite_gpr_with_best_model(df, results_df):
    """
    Update the GPR composite rating calculator to use the best forecasting model
    for each country based on the evaluation results.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        DataFrame containing the GPR data from SQL
    results_df : pandas.DataFrame
        DataFrame with model evaluation results
        
    Returns:
    --------
    dict
        Dictionary mapping each country code to its best forecasting model function
    """
    # Create a mapping of country codes to best model functions
    country_best_models = {}
    
    for _, row in results_df.iterrows():
        country_code = row['Country Code']
        best_model_name = row['Best Model']
        
        # Define the model function based on the best model name
        if best_model_name.startswith('ARIMA'):
            # Extract p, d, q parameters from model name
            params = best_model_name.split('(')[1].split(')')[0].split(',')
            p, d, q = int(params[0]), int(params[1]), int(params[2])
            model_func = lambda ts, p=p, d=d, q=q: ARIMA(ts, order=(p, d, q))
            
        elif best_model_name.startswith('SARIMA'):
            # Extract parameters from model name
            main_params = best_model_name.split('(')[1].split(')')[0].split(',')
            seasonal_params = best_model_name.split('(')[2].split(')')[0].split(',')
            
            p, d, q = int(main_params[0]), int(main_params[1]), int(main_params[2])
            P, D, Q, m = int(seasonal_params[0]), int(seasonal_params[1]), int(seasonal_params[2]), int(seasonal_params[3])
            
            model_func = lambda ts, p=p, d=d, q=q, P=P, D=D, Q=Q, m=m: SARIMAX(
                ts, order=(p, d, q), seasonal_order=(P, D, Q, m)
            )
            
        elif best_model_name == 'Holt-Winters':
            model_func = lambda ts: ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=12)
            
        elif best_model_name.startswith('Simple MA'):
            window = int(best_model_name.split('(')[1].split(')')[0])
            
            def ma_forecast(ts, window=window, steps=1):
                forecast = []
                for _ in range(steps):
                    if not forecast:
                        # First forecast point
                        forecast.append(ts.iloc[-window:].mean())
                    else:
                        # Use previous forecasts in the window
                        window_data = pd.concat([ts.iloc[-(window-len(forecast)):], pd.Series(forecast)])
                        forecast.append(window_data.mean())
                return forecast
            
            model_func = ma_forecast
        
        country_best_models[country_code] = model_func
    
    return country_best_models

def main():
    # Define SQL connection parameters
    connection_string = "mssql+pyodbc://username:password@server/database?driver=ODBC+Driver+17+for+SQL+Server"
    
    # Define SQL query to retrieve GPR data
    # Adjust the query based on your database schema
    query = """
    SELECT 
        month, 
        GPR, GPRT, GPRA, GPRH, GPRHT, GPRHA, 
        SHARE_GPR, N10, SHARE_GPRH, N3H, 
        GPRH_NOEW, GPR_NOEW, GPRH_AND, GPR_AND, 
        GPRH_BASIC, GPR_BASIC, 
        SHAREH_CAT_1, SHAREH_CAT_2, SHAREH_CAT_3, 
        SHAREH_CAT_4, SHAREH_CAT_5, SHAREH_CAT_6, 
        SHAREH_CAT_7, SHAREH_CAT_8,
        -- Add all country columns
        GPRC_ARG, GPRC_AUS, GPRC_BEL, GPRC_BRA, GPRC_CAN, 
        GPRC_CHE, GPRC_CHL, GPRC_CHN, GPRC_COL, GPRC_DEU, 
        GPRC_DNK, GPRC_EGY, GPRC_ESP, GPRC_FIN, GPRC_FRA, 
        GPRC_GBR, GPRC_HKG, GPRC_HUN, GPRC_IDN, GPRC_IND, 
        GPRC_ISR, GPRC_ITA, GPRC_JPN, GPRC_KOR, GPRC_MEX, 
        GPRC_MYS, GPRC_NLD, GPRC_NOR, GPRC_PER, GPRC_PHL, 
        GPRC_POL, GPRC_PRT, GPRC_RUS, GPRC_SAU, GPRC_SWE, 
        GPRC_THA, GPRC_TUN, GPRC_TUR, GPRC_TWN, GPRC_UKR, 
        GPRC_USA, GPRC_VEN, GPRC_VNM, GPRC_ZAF,
        GPRHC_ARG, GPRHC_AUS, GPRHC_BEL, GPRHC_BRA, GPRHC_CAN, 
        GPRHC_CHE, GPRHC_CHL, GPRHC_CHN, GPRHC_COL, GPRHC_DEU, 
        GPRHC_DNK, GPRHC_EGY, GPRHC_ESP, GPRHC_FIN, GPRHC_FRA, 
        GPRHC_GBR, GPRHC_HKG, GPRHC_HUN, GPRHC_IDN, GPRHC_IND, 
        GPRHC_ISR, GPRHC_ITA, GPRHC_JPN, GPRHC_KOR, GPRHC_MEX, 
        GPRHC_MYS, GPRHC_NLD, GPRHC_NOR, GPRHC_PER, GPRHC_PHL, 
        GPRHC_POL, GPRHC_PRT, GPRHC_RUS, GPRHC_SAU, GPRHC_SWE, 
        GPRHC_THA, GPRHC_TUN, GPRHC_TUR, GPRHC_TWN, GPRHC_UKR, 
        GPRHC_USA, GPRHC_VEN, GPRHC_VNM, GPRHC_ZAF,
        var_name, var_label
    FROM 
        gpr_data
    """
    
    try:
        # Get data from SQL
        df = get_data_from_sql(connection_string, query)
        
        # Evaluate forecast models for all countries
        results_df = evaluate_forecast_models(df, test_size=12)
        
        # Display results of individual countries, sorted by highest R² (best fit)
        print("\nBest Forecast Models by Country (Sorted by Highest R²):")
        display(results_df[['Country Name', 'Best Model', 'R2', 'RMSE']])
        
        # Find the best overall model (highest average R²)
        model_avg_df = find_best_overall_model(results_df)
        
        print("\nForecast Models Ranked by Average R² (Highest First):")
        display(model_avg_df)
        
        # Determine the model with the highest average R²
        best_model = model_avg_df.iloc[0]['Model']
        best_avg_r2 = model_avg_df.iloc[0]['Average R2']
        print(f"\nThe model with the highest average R² is: {best_model} (Average R² = {best_avg_r2:.4f})")
        
        # Find the country-model combination with the absolute highest R²
        best_country_idx = results_df['R2'].idxmax()
        best_country = results_df.loc[best_country_idx]
        print(f"\nThe highest individual R² was achieved by: {best_country['Best Model']} for {best_country['Country Name']} (R² = {best_country['R2']:.4f})")
        
        # Create mapping of countries to best forecast models
        country_best_models = update_composite_gpr_with_best_model(df, results_df)
        
        # Return results for further processing
        return results_df, model_avg_df, country_best_models
    
    except Exception as e:
        print(f"Error in main function: {str(e)}")
        return None, None, None

if __name__ == "__main__":
    main()
