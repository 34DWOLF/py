import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.stattools import adfuller
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, explained_variance_score
from scipy import stats
from itertools import product
import re
import warnings
warnings.filterwarnings('ignore')

def evaluate_forecast_models(file_path, country_codes=None, test_size=12):
    """
    Evaluate multiple forecasting models for GPR data and find the best model
    based on highest R² values for each country.
    
    Parameters:
    -----------
    file_path : str
        Path to the CSV file containing GPR data
    country_codes : list, optional
        List of country codes to evaluate (if None, evaluate all countries)
    test_size : int, optional
        Number of months to use for testing (default: 12 months)
        
    Returns:
    --------
    pandas.DataFrame
        DataFrame containing the best model for each country
    """
    # Read the data
    df = pd.read_csv(file_path)
    print(f"Data loaded with {len(df)} rows")
    
    # Convert month column to datetime
    df['date'] = pd.to_datetime(df['month'])
    
    # Get all country codes from columns if not provided
    if country_codes is None:
        current_gpr_cols = [col for col in df.columns if col.startswith('GPRC_')]
        country_codes = [col.split('_')[1] for col in current_gpr_cols]
    
    print(f"Evaluating forecast models for {len(country_codes)} countries")
    
    # Create a mapping of country codes to country names
    country_names = {}
    if 'var_name' in df.columns and 'var_label' in df.columns:
        for _, row in df.drop_duplicates('var_name').iterrows():
            if isinstance(row['var_name'], str) and isinstance(row['var_label'], str):
                if row['var_name'].startswith('GPRC_'):
                    country_code = row['var_name'].split('_')[1]
                    country_name_match = re.search(r'\((.*?)\)$', row['var_label'])
                    if country_name_match:
                        country_name = country_name_match.group(1)
                        country_names[country_code] = country_name
    
    # Sort data by date
    df = df.sort_values('date')
    
    # Define models to evaluate
    models = {
        'ARIMA(1,1,1)': lambda ts: ARIMA(ts, order=(1, 1, 1)),
        'ARIMA(2,1,2)': lambda ts: ARIMA(ts, order=(2, 1, 2)),
        'ARIMA(3,1,3)': lambda ts: ARIMA(ts, order=(3, 1, 3)),
        'ARIMA(2,1,0)': lambda ts: ARIMA(ts, order=(2, 1, 0)),  # AR only
        'ARIMA(0,1,2)': lambda ts: ARIMA(ts, order=(0, 1, 2)),  # MA only
        'SARIMA(1,1,1)(1,0,1,12)': lambda ts: SARIMAX(ts, order=(1, 1, 1), seasonal_order=(1, 0, 1, 12)),
        'SARIMA(2,1,2)(1,0,1,12)': lambda ts: SARIMAX(ts, order=(2, 1, 2), seasonal_order=(1, 0, 1, 12)),
        'Holt-Winters': lambda ts: ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=12),
        'Simple MA(3)': lambda ts: None,  # Special case handled separately
        'Simple MA(6)': lambda ts: None,  # Special case handled separately
        'Simple MA(12)': lambda ts: None,  # Special case handled separately
    }
    
    # Initialize results DataFrame
    results = []
    
    # Evaluate each country
    for i, country_code in enumerate(country_codes):
        print(f"Processing country {i+1}/{len(country_codes)}: {country_code}")
        
        # Get the GPR column for this country
        gpr_col = f'GPRC_{country_code}'
        
        # Skip if the column doesn't exist
        if gpr_col not in df.columns:
            print(f"Column {gpr_col} not found, skipping")
            continue
        
        # Get the GPR time series
        ts = df[gpr_col].dropna()
        
        # Skip if not enough data
        if len(ts) < test_size + 24:  # Need at least 24 months for training + test_size for testing
            print(f"Not enough data for {country_code}, skipping")
            continue
        
        # Split into train and test sets
        train = ts.iloc[:-test_size]
        test = ts.iloc[-test_size:]
        
        # Initialize metrics for each model
        model_metrics = {}
        
        # Test each model
        for model_name, model_func in models.items():
            try:
                if model_name.startswith('Simple MA'):
                    # Extract window size from model name
                    window = int(model_name.split('(')[1].split(')')[0])
                    
                    # Generate forecast using simple moving average
                    forecast = []
                    for i in range(len(test)):
                        # Get the window of data ending at the last known point
                        if i == 0:
                            window_data = train.iloc[-window:]
                        else:
                            # Combine known train data with the forecasts we've already made
                            window_data = pd.concat([train.iloc[-(window-i):], pd.Series(forecast[:i])])
                        
                        # Calculate the moving average
                        forecast.append(window_data.mean())
                    
                    # For MA models, we need to manually calculate the model fit info
                    residuals = test - forecast
                    model_summary = None
                    f_statistic = None
                    p_value = None
                    
                else:
                    # Fit the model
                    model = model_func(train)
                    if isinstance(model, (ARIMA, SARIMAX)):
                        fitted = model.fit()
                        # Generate forecast
                        forecast = fitted.forecast(steps=len(test))
                        # Get model summary for F-Statistic
                        model_summary = fitted.summary()
                        
                        # Calculate F-Statistic from the model
                        # F = (ESS/df_model) / (RSS/df_resid)
                        f_statistic = fitted.fittedvalues.var() / fitted.resid.var()
                        # Calculate p-value from F-statistic
                        df_model = len(fitted.params)
                        df_resid = len(fitted.resid) - df_model
                        p_value = 1 - stats.f.cdf(f_statistic, df_model, df_resid)
                        
                        residuals = test - forecast
                        
                    else:  # Holt-Winters
                        fitted = model.fit()
                        # Generate forecast
                        forecast = fitted.forecast(len(test))
                        # We don't have model summary for Holt-Winters
                        model_summary = None
                        f_statistic = None
                        p_value = None
                        residuals = test - forecast
                
                # Calculate metrics
                r2 = r2_score(test, forecast)
                mse = mean_squared_error(test, forecast)
                mae = mean_absolute_error(test, forecast)
                rmse = np.sqrt(mse)
                
                # Calculate Residual Sum of Squares (RSS)
                rss = np.sum(np.square(residuals))
                
                # Calculate Total Sum of Squares (TSS)
                tss = np.sum(np.square(test - test.mean()))
                
                # Calculate Explained Sum of Squares (ESS)
                ess = tss - rss
                
                # Calculate Explained Variance
                explained_var = explained_variance_score(test, forecast)
                
                model_metrics[model_name] = {
                    'R2': r2,
                    'MSE': mse,
                    'MAE': mae,
                    'RMSE': rmse,
                    'RSS': rss,
                    'ESS': ess,
                    'TSS': tss,
                    'F_Statistic': f_statistic,
                    'P_Value': p_value,
                    'Explained_Variance': explained_var
                }
                
                print(f"  {model_name}: R² = {r2:.4f}, RMSE = {rmse:.4f}, F = {f_statistic if f_statistic is not None else 'N/A'}")
            
            except Exception as e:
                print(f"  Error with {model_name} for {country_code}: {str(e)}")
        
        # Find the best model based on highest R²
        if model_metrics:
            best_model = max(model_metrics.items(), key=lambda x: x[1]['R2'])
            
            results.append({
                'Country Code': country_code,
                'Country Name': country_names.get(country_code, country_code),
                'Best Model': best_model[0],
                'R2': best_model[1]['R2'],
                'MSE': best_model[1]['MSE'],
                'MAE': best_model[1]['MAE'],
                'RMSE': best_model[1]['RMSE'],
                'RSS': best_model[1]['RSS'],
                'ESS': best_model[1]['ESS'],
                'TSS': best_model[1]['TSS'],
                'F_Statistic': best_model[1]['F_Statistic'],
                'P_Value': best_model[1]['P_Value'],
                'Explained_Variance': best_model[1]['Explained_Variance'],
                'All Models': model_metrics
            })
    
    # Convert results to DataFrame
    results_df = pd.DataFrame(results)
    
    # Sort by highest R² (best fit)
    results_df = results_df.sort_values('R2', ascending=False)
    
    return results_df

def find_best_overall_model(results_df):
    """
    Analyzes the results to find the forecasting model with the 
    highest average R² across all countries.
    
    Parameters:
    -----------
    results_df : pandas.DataFrame
        DataFrame with model evaluation results
        
    Returns:
    --------
    pandas.DataFrame
        DataFrame with average R² for each model type
    """
    # Calculate average metrics by model type
    model_performance = {}
    
    metric_keys = ['R2', 'MSE', 'MAE', 'RMSE', 'RSS', 'ESS', 'TSS', 
                   'F_Statistic', 'P_Value', 'Explained_Variance']
    
    for _, row in results_df.iterrows():
        all_models = row['All Models']
        for model_name, metrics in all_models.items():
            if model_name not in model_performance:
                model_performance[model_name] = {
                    'count': 0
                }
                # Initialize sum and values for each metric
                for key in metric_keys:
                    model_performance[model_name][f'{key}_sum'] = 0
                    model_performance[model_name][f'{key}_values'] = []
            
            # Update count
            model_performance[model_name]['count'] += 1
            
            # Update sums and values for each metric
            for key in metric_keys:
                if key in metrics and metrics[key] is not None:
                    model_performance[model_name][f'{key}_sum'] += metrics[key]
                    model_performance[model_name][f'{key}_values'].append(metrics[key])
    
    # Calculate average, median, max, min, and std dev for each metric
    for model_name in model_performance:
        for key in metric_keys:
            values = model_performance[model_name][f'{key}_values']
            if values:
                model_performance[model_name][f'Average_{key}'] = model_performance[model_name][f'{key}_sum'] / len(values)
                model_performance[model_name][f'Median_{key}'] = np.median(values)
                model_performance[model_name][f'Max_{key}'] = np.max(values)
                model_performance[model_name][f'Min_{key}'] = np.min(values)
                model_performance[model_name][f'Std_{key}'] = np.std(values)
            else:
                model_performance[model_name][f'Average_{key}'] = None
                model_performance[model_name][f'Median_{key}'] = None
                model_performance[model_name][f'Max_{key}'] = None
                model_performance[model_name][f'Min_{key}'] = None
                model_performance[model_name][f'Std_{key}'] = None
    
    # Convert to DataFrame
    metrics_to_include = ['Average_R2', 'Median_R2', 'Max_R2', 'Min_R2', 'Std_R2',
                          'Average_RMSE', 'Average_MSE', 'Average_MAE', 
                          'Average_F_Statistic', 'Average_RSS', 'Average_Explained_Variance']
    
    model_avg_df = pd.DataFrame([
        {
            'Model': model_name,
            'Count': stats['count'],
            **{metric: stats.get(metric) for metric in metrics_to_include if metric in stats}
        }
        for model_name, stats in model_performance.items()
    ])
    
    # Sort by average R² (highest first)
    model_avg_df = model_avg_df.sort_values('Average_R2', ascending=False)
    
    return model_avg_df

def generate_forecast_visualizations(file_path, country_code, test_size=12):
    """
    Generate visualizations of actual vs. forecasted GPR values
    using different models for a specific country.
    
    Parameters:
    -----------
    file_path : str
        Path to the CSV file containing GPR data
    country_code : str
        Country code to analyze
    test_size : int, optional
        Number of months to use for testing
    """
    # Read the data
    df = pd.read_csv(file_path)
    
    # Convert month column to datetime
    df['date'] = pd.to_datetime(df['month'])
    
    # Sort data by date
    df = df.sort_values('date')
    
    # Get the GPR column for this country
    gpr_col = f'GPRC_{country_code}'
    
    # Get the GPR time series
    ts = df[gpr_col].dropna()
    
    # Split into train and test sets
    train = ts.iloc[:-test_size]
    test = ts.iloc[-test_size:]
    test_dates = df['date'].iloc[-test_size:]
    
    # Define models to test
    models = {
        'ARIMA(1,1,1)': ARIMA(train, order=(1, 1, 1)),
        'ARIMA(2,1,2)': ARIMA(train, order=(2, 1, 2)),
        'SARIMA(1,1,1)(1,0,1,12)': SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 0, 1, 12)),
        'Holt-Winters': ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=12)
    }
    
    # Create a figure
    plt.figure(figsize=(12, 8))
    
    # Plot actual values
    plt.plot(test_dates, test, 'k-', label='Actual')
    
    # Initialize metrics table
    metrics_table = []
    
    # Plot forecasts for each model
    for model_name, model in models.items():
        try:
            if isinstance(model, (ARIMA, SARIMAX)):
                fitted = model.fit()
                # Generate forecast
                forecast = fitted.forecast(steps=len(test))
            else:  # Holt-Winters
                fitted = model.fit()
                # Generate forecast
                forecast = fitted.forecast(len(test))
            
            # Calculate metrics
            r2 = r2_score(test, forecast)
            mse = mean_squared_error(test, forecast)
            mae = mean_absolute_error(test, forecast)
            rmse = np.sqrt(mse)
            
            # Calculate Residual Sum of Squares (RSS)
            residuals = test - forecast
            rss = np.sum(np.square(residuals))
            
            # Calculate Total Sum of Squares (TSS)
            tss = np.sum(np.square(test - test.mean()))
            
            # Calculate Explained Sum of Squares (ESS)
            ess = tss - rss
            
            # Calculate Explained Variance
            explained_var = explained_variance_score(test, forecast)
            
            # Store metrics
            metrics_table.append({
                'Model': model_name,
                'R²': r2,
                'RMSE': rmse,
                'MSE': mse,
                'MAE': mae,
                'RSS': rss,
                'ESS': ess,
                'Explained Variance': explained_var
            })
            
            # Plot forecast
            plt.plot(test_dates, forecast, '--', label=f'{model_name} (R² = {r2:.4f})')
        
        except Exception as e:
            print(f"Error with {model_name} for {country_code}: {str(e)}")
    
    # Add labels and title
    plt.xlabel('Date')
    plt.ylabel('GPR')
    plt.title(f'Forecasting Models Comparison for {country_code}')
    plt.legend()
    plt.grid(True)
    
    # Show the plot
    plt.tight_layout()
    plt.show()
    
    # Display metrics table
    metrics_df = pd.DataFrame(metrics_table)
    display(metrics_df)
    
    return metrics_df

def main():
    # File path to the GPR data
    file_path = ''
    
    # Evaluate forecast models for all countries
    results_df = evaluate_forecast_models(file_path, test_size=12)
    
    # Display results of individual countries, sorted by highest R² (best fit)
    print("\nBest Forecast Models by Country (Sorted by Highest R²):")
    display_cols = ['Country Name', 'Best Model', 'R2', 'RMSE', 'MSE', 'MAE', 
                    'RSS', 'Explained_Variance', 'F_Statistic']
    display(results_df[display_cols])
    
    # Find the best overall model (highest average R²)
    model_avg_df = find_best_overall_model(results_df)
    
    print("\nForecast Models Ranked by Average R² (Highest First):")
    display(model_avg_df)
    
    # Determine the model with the highest average R²
    best_model = model_avg_df.iloc[0]['Model']
    best_avg_r2 = model_avg_df.iloc[0]['Average_R2']
    best_avg_rmse = model_avg_df.iloc[0]['Average_RMSE']
    print(f"\nThe model with the highest average R² is: {best_model}")
    print(f"Average R² = {best_avg_r2:.4f}")
    print(f"Average RMSE = {best_avg_rmse:.4f}")
    
    # Find the country-model combination with the absolute highest R²
    best_country_idx = results_df['R2'].idxmax()
    best_country = results_df.loc[best_country_idx]
    print(f"\nThe highest individual R² was achieved by: {best_country['Best Model']} for {best_country['Country Name']}")
    print(f"R² = {best_country['R2']:.4f}")
    print(f"RMSE = {best_country['RMSE']:.4f}")
    print(f"MSE = {best_country['MSE']:.4f}")
    print(f"MAE = {best_country['MAE']:.4f}")
    print(f"RSS = {best_country['RSS']:.4f}")
    print(f"Explained Variance = {best_country['Explained_Variance']:.4f}")
    if best_country['F_Statistic'] is not None:
        print(f"F-Statistic = {best_country['F_Statistic']:.4f} (p = {best_country['P_Value']:.4f})")
    
    # Optionally: Generate visualizations for a specific country
    # country_to_visualize = 'USA'
    # print(f"\nGenerating visualizations for {country_to_visualize}...")
    # generate_forecast_visualizations(file_path, country_to_visualize)
    
    return results_df, model_avg_df

if __name__ == "__main__":
    import re  # Import re at the top level
    main()
