import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.stattools import adfuller
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from itertools import product
import warnings
warnings.filterwarnings('ignore')

def evaluate_forecast_models(file_path, country_codes=None, test_size=12):
    """
    Evaluate multiple forecasting models for GPR data and find the best model
    based on highest R² values for each country.
    
    Parameters:
    -----------
    file_path : str
        Path to the CSV file containing GPR data
    country_codes : list, optional
        List of country codes to evaluate (if None, evaluate all countries)
    test_size : int, optional
        Number of months to use for testing (default: 12 months)
        
    Returns:
    --------
    pandas.DataFrame
        DataFrame containing the best model for each country
    """
    # Read the data
    df = pd.read_csv(file_path)
    print(f"Data loaded with {len(df)} rows")
    
    # Convert month column to datetime
    df['date'] = pd.to_datetime(df['month'])
    
    # Get all country codes from columns if not provided
    if country_codes is None:
        current_gpr_cols = [col for col in df.columns if col.startswith('GPRC_')]
        country_codes = [col.split('_')[1] for col in current_gpr_cols]
    
    print(f"Evaluating forecast models for {len(country_codes)} countries")
    
    # Create a mapping of country codes to country names
    country_names = {}
    if 'var_name' in df.columns and 'var_label' in df.columns:
        for _, row in df.drop_duplicates('var_name').iterrows():
            if isinstance(row['var_name'], str) and isinstance(row['var_label'], str):
                if row['var_name'].startswith('GPRC_'):
                    country_code = row['var_name'].split('_')[1]
                    country_name_match = re.search(r'\((.*?)\)$', row['var_label'])
                    if country_name_match:
                        country_name = country_name_match.group(1)
                        country_names[country_code] = country_name
    
    # Sort data by date
    df = df.sort_values('date')
    
    # Define models to evaluate
    models = {
        'ARIMA(1,1,1)': lambda ts: ARIMA(ts, order=(1, 1, 1)),
        'ARIMA(2,1,2)': lambda ts: ARIMA(ts, order=(2, 1, 2)),
        'ARIMA(3,1,3)': lambda ts: ARIMA(ts, order=(3, 1, 3)),
        'ARIMA(2,1,0)': lambda ts: ARIMA(ts, order=(2, 1, 0)),  # AR only
        'ARIMA(0,1,2)': lambda ts: ARIMA(ts, order=(0, 1, 2)),  # MA only
        'SARIMA(1,1,1)(1,0,1,12)': lambda ts: SARIMAX(ts, order=(1, 1, 1), seasonal_order=(1, 0, 1, 12)),
        'SARIMA(2,1,2)(1,0,1,12)': lambda ts: SARIMAX(ts, order=(2, 1, 2), seasonal_order=(1, 0, 1, 12)),
        'Holt-Winters': lambda ts: ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=12),
        'Simple MA(3)': lambda ts: None,  # Special case handled separately
        'Simple MA(6)': lambda ts: None,  # Special case handled separately
        'Simple MA(12)': lambda ts: None,  # Special case handled separately
    }
    
    # Initialize results DataFrame
    results = []
    
    # Evaluate each country
    for i, country_code in enumerate(country_codes):
        print(f"Processing country {i+1}/{len(country_codes)}: {country_code}")
        
        # Get the GPR column for this country
        gpr_col = f'GPRC_{country_code}'
        
        # Skip if the column doesn't exist
        if gpr_col not in df.columns:
            print(f"Column {gpr_col} not found, skipping")
            continue
        
        # Get the GPR time series
        ts = df[gpr_col].dropna()
        
        # Skip if not enough data
        if len(ts) < test_size + 24:  # Need at least 24 months for training + test_size for testing
            print(f"Not enough data for {country_code}, skipping")
            continue
        
        # Split into train and test sets
        train = ts.iloc[:-test_size]
        test = ts.iloc[-test_size:]
        
        # Initialize metrics for each model
        model_metrics = {}
        
        # Test each model
        for model_name, model_func in models.items():
            try:
                if model_name.startswith('Simple MA'):
                    # Extract window size from model name
                    window = int(model_name.split('(')[1].split(')')[0])
                    
                    # Generate forecast using simple moving average
                    forecast = []
                    for i in range(len(test)):
                        # Get the window of data ending at the last known point
                        if i == 0:
                            window_data = train.iloc[-window:]
                        else:
                            # Combine known train data with the forecasts we've already made
                            window_data = pd.concat([train.iloc[-(window-i):], pd.Series(forecast[:i])])
                        
                        # Calculate the moving average
                        forecast.append(window_data.mean())
                else:
                    # Fit the model
                    model = model_func(train)
                    if isinstance(model, (ARIMA, SARIMAX)):
                        fitted = model.fit()
                        # Generate forecast
                        forecast = fitted.forecast(steps=len(test))
                    else:  # Holt-Winters
                        fitted = model.fit()
                        # Generate forecast
                        forecast = fitted.forecast(len(test))
                
                # Calculate metrics
                r2 = r2_score(test, forecast)
                mse = mean_squared_error(test, forecast)
                mae = mean_absolute_error(test, forecast)
                rmse = np.sqrt(mse)
                
                model_metrics[model_name] = {
                    'R2': r2,
                    'MSE': mse,
                    'MAE': mae,
                    'RMSE': rmse
                }
                
                print(f"  {model_name}: R² = {r2:.4f}, RMSE = {rmse:.4f}")
            
            except Exception as e:
                print(f"  Error with {model_name} for {country_code}: {str(e)}")
        
        # Find the best model based on highest R²
        if model_metrics:
            best_model = max(model_metrics.items(), key=lambda x: x[1]['R2'])
            
            results.append({
                'Country Code': country_code,
                'Country Name': country_names.get(country_code, country_code),
                'Best Model': best_model[0],
                'R2': best_model[1]['R2'],
                'MSE': best_model[1]['MSE'],
                'MAE': best_model[1]['MAE'],
                'RMSE': best_model[1]['RMSE'],
                'All Models': model_metrics
            })
    
    # Convert results to DataFrame
    results_df = pd.DataFrame(results)
    
    # Sort by highest R² (best fit)
    results_df = results_df.sort_values('R2', ascending=False)
    
    return results_df

def find_best_overall_model(results_df):
    """
    Analyzes the results to find the forecasting model with the 
    highest average R² across all countries.
    
    Parameters:
    -----------
    results_df : pandas.DataFrame
        DataFrame with model evaluation results
        
    Returns:
    --------
    pandas.DataFrame
        DataFrame with average R² for each model type
    """
    # Calculate average R² by model type
    model_performance = {}
    
    for _, row in results_df.iterrows():
        all_models = row['All Models']
        for model_name, metrics in all_models.items():
            if model_name not in model_performance:
                model_performance[model_name] = {
                    'R2_sum': 0, 
                    'R2_values': [], 
                    'count': 0
                }
            
            model_performance[model_name]['R2_sum'] += metrics['R2']
            model_performance[model_name]['R2_values'].append(metrics['R2'])
            model_performance[model_name]['count'] += 1
    
    # Calculate average R² and other stats for each model
    for model_name in model_performance:
        r2_values = model_performance[model_name]['R2_values']
        model_performance[model_name].update({
            'Average_R2': model_performance[model_name]['R2_sum'] / model_performance[model_name]['count'],
            'Median_R2': np.median(r2_values),
            'Max_R2': np.max(r2_values),
            'Min_R2': np.min(r2_values),
            'Std_R2': np.std(r2_values)
        })
    
    # Convert to DataFrame and sort by average R² (highest first)
    model_avg_df = pd.DataFrame([
        {
            'Model': model_name, 
            'Average R2': stats['Average_R2'], 
            'Median R2': stats['Median_R2'],
            'Max R2': stats['Max_R2'],
            'Min R2': stats['Min_R2'],
            'Std Dev R2': stats['Std_R2'],
            'Count': stats['count']
        }
        for model_name, stats in model_performance.items()
    ])
    
    model_avg_df = model_avg_df.sort_values('Average R2', ascending=False)
    
    return model_avg_df

def generate_forecast_visualizations(file_path, country_code, test_size=12):
    """
    Generate visualizations of actual vs. forecasted GPR values
    using different models for a specific country.
    
    Parameters:
    -----------
    file_path : str
        Path to the CSV file containing GPR data
    country_code : str
        Country code to analyze
    test_size : int, optional
        Number of months to use for testing
    """
    # Read the data
    df = pd.read_csv(file_path)
    
    # Convert month column to datetime
    df['date'] = pd.to_datetime(df['month'])
    
    # Sort data by date
    df = df.sort_values('date')
    
    # Get the GPR column for this country
    gpr_col = f'GPRC_{country_code}'
    
    # Get the GPR time series
    ts = df[gpr_col].dropna()
    
    # Split into train and test sets
    train = ts.iloc[:-test_size]
    test = ts.iloc[-test_size:]
    test_dates = df['date'].iloc[-test_size:]
    
    # Define models to test
    models = {
        'ARIMA(1,1,1)': ARIMA(train, order=(1, 1, 1)),
        'ARIMA(2,1,2)': ARIMA(train, order=(2, 1, 2)),
        'SARIMA(1,1,1)(1,0,1,12)': SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 0, 1, 12)),
        'Holt-Winters': ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=12)
    }
    
    # Create a figure
    plt.figure(figsize=(12, 8))
    
    # Plot actual values
    plt.plot(test_dates, test, 'k-', label='Actual')
    
    # Plot forecasts for each model
    for model_name, model in models.items():
        try:
            if isinstance(model, (ARIMA, SARIMAX)):
                fitted = model.fit()
                forecast = fitted.forecast(steps=len(test))
            else:  # Holt-Winters
                fitted = model.fit()
                forecast = fitted.forecast(len(test))
            
            # Calculate R²
            r2 = r2_score(test, forecast)
            
            # Plot forecast
            plt.plot(test_dates, forecast, '--', label=f'{model_name} (R² = {r2:.4f})')
        
        except Exception as e:
            print(f"Error with {model_name} for {country_code}: {str(e)}")
    
    # Add labels and title
    plt.xlabel('Date')
    plt.ylabel('GPR')
    plt.title(f'Forecasting Models Comparison for {country_code}')
    plt.legend()
    plt.grid(True)
    
    # Show the plot
    plt.tight_layout()
    plt.show()

def main():
    # File path to the GPR data
    file_path = ''
    
    # Evaluate forecast models for all countries
    results_df = evaluate_forecast_models(file_path, test_size=12)
    
    # Display results of individual countries, sorted by highest R² (best fit)
    print("\nBest Forecast Models by Country (Sorted by Highest R²):")
    display(results_df[['Country Name', 'Best Model', 'R2', 'RMSE']])
    
    # Find the best overall model (highest average R²)
    model_avg_df = find_best_overall_model(results_df)
    
    print("\nForecast Models Ranked by Average R² (Highest First):")
    display(model_avg_df)
    
    # Determine the model with the highest average R²
    best_model = model_avg_df.iloc[0]['Model']
    best_avg_r2 = model_avg_df.iloc[0]['Average R2']
    print(f"\nThe model with the highest average R² is: {best_model} (Average R² = {best_avg_r2:.4f})")
    
    # Find the country-model combination with the absolute highest R²
    best_country_idx = results_df['R2'].idxmax()
    best_country = results_df.loc[best_country_idx]
    print(f"\nThe highest individual R² was achieved by: {best_country['Best Model']} for {best_country['Country Name']} (R² = {best_country['R2']:.4f})")
    
    # Optionally: Generate visualizations for a specific country
    # generate_forecast_visualizations(file_path, 'USA')
    
    return results_df, model_avg_df

if __name__ == "__main__":
    import re  # Import re at the top level
    main()
