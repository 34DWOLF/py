# Import required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller, acf, pacf
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.linear_model import LinearRegression
from datetime import datetime, timedelta
import warnings
from dateutil.relativedelta import relativedelta
import logging

# ====================================================
# PARAMETER SECTION - Modify these values as needed
# ====================================================
# Minimum number of months required for ARIMA modeling
MIN_MONTHS_FOR_ARIMA = 24  # At least 2 years of data required for ARIMA

# Minimum number of months required for stationarity testing
MIN_MONTHS_FOR_STATIONARITY = 8

# Number of months to forecast
FORECAST_MONTHS = 12

# Maximum lags to consider for ACF/PACF analysis
MAX_LAGS_DEFAULT = 10
MAX_LAGS_SEASONAL = 24

# Confidence interval level (%)
CONFIDENCE_LEVEL = 95
Z_VALUE = 1.96  # Corresponds to 95% confidence

# Reconciliation method
# Options: "proportional", "weight_forecast", "weight_history"
RECONCILIATION_METHOD = "proportional"  

# Plot settings
FIGSIZE_TIMESERIES = (14, 7)
FIGSIZE_ACF_PACF = (12, 8)
# ====================================================

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('forecast_model')

# Suppress warnings for cleaner output
warnings.filterwarnings("ignore")

# Set plot style for better visualizations
plt.style.use('seaborn-whitegrid')

# Load data (replace with your actual file path in Databricks)
file_path = "/dbfs/FileStore/your_data_file.csv"  # Update this path
logger.info(f"Loading data from {file_path}")
df = pd.read_csv(file_path)

# Ensure Date is in datetime format
df['Date'] = pd.to_datetime(df['Date'])

# Since data is monthly, ensure it's set to the first day of each month for consistency
df['Date'] = df['Date'].apply(lambda x: x.replace(day=1))
logger.info(f"Data loaded successfully with {len(df)} rows")

# Display the first few rows
print("Data sample:")
display(df.head())

# Get basic statistics
print("\nData summary:")
display(df.describe())

# Check for missing values
print("\nMissing values:")
display(df.isnull().sum())

# Get unique owners
all_owners = df['Owner'].unique()
logger.info(f"Found {len(all_owners)} unique owners")

# Separate "Total" from other owners
is_total_present = "Total" in all_owners
if is_total_present:
    other_owners = [owner for owner in all_owners if owner != "Total"]
    logger.info(f"Found 'Total' owner and {len(other_owners)} other owners")
else:
    other_owners = all_owners
    logger.info("No 'Total' owner found, treating all owners individually")

print(f"\nNumber of unique owners: {len(all_owners)}")
print("Owners:", all_owners)

# Count data points per owner
owner_counts = df.groupby('Owner').size().reset_index(name='Count')
print("\nData points per owner:")
display(owner_counts)

# Check date ranges per owner
date_ranges = []
for owner in all_owners:
    owner_data = df[df['Owner'] == owner].sort_values('Date')
    date_ranges.append({
        'Owner': owner,
        'First Month': owner_data['Date'].min().strftime('%Y-%m'),
        'Last Month': owner_data['Date'].max().strftime('%Y-%m'),
        'Months Count': len(owner_data),
        'Is Continuous': len(owner_data) == ((owner_data['Date'].max() - owner_data['Date'].min()).days // 30) + 1
    })

date_range_df = pd.DataFrame(date_ranges)
print("\nDate ranges per owner:")
display(date_range_df)

# Define stationarity check function
def check_stationarity(timeseries, owner_name=None):
    """
    Test stationarity using Augmented Dickey-Fuller test
    """
    # Perform ADF test
    result = adfuller(timeseries)
    
    # Extract results
    dftest = pd.Series(
        result[0:4],
        index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used']
    )
    
    for key, value in result[4].items():
        dftest[f'Critical Value ({key})'] = value
    
    # Determine if stationary
    is_stationary = result[1] <= 0.05
    
    # Display results
    if owner_name:
        print(f"Results of Augmented Dickey-Fuller Test for Owner: {owner_name}")
    else:
        print("Results of Augmented Dickey-Fuller Test:")
    
    print(dftest)
    print(f"Is the series stationary? {'Yes' if is_stationary else 'No'}")
    print("-" * 50)
    
    return is_stationary, result[1]

# Plot time series for each owner
logger.info("Plotting time series for each owner")
plt.figure(figsize=(FIGSIZE_TIMESERIES[0], len(all_owners) * 4))

for i, owner in enumerate(all_owners):
    owner_data = df[df['Owner'] == owner].sort_values('Date')
    
    plt.subplot(len(all_owners), 1, i+1)
    plt.plot(owner_data['Date'], owner_data['Value'], marker='o', linestyle='-', label=f"Data Points: {len(owner_data)}")
    plt.title(f'Monthly Time Series for Owner: {owner}')
    plt.ylabel('Value')
    plt.grid(True)
    plt.legend()
    
    # Format x-axis to show month-year
    plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%b %Y'))
    plt.gcf().autofmt_xdate()

plt.tight_layout()
display(plt.gcf())
plt.close()

# Test stationarity for each owner
logger.info("Testing stationarity for each owner")
stationarity_results = {}

for owner in all_owners:
    owner_data = df[df['Owner'] == owner].sort_values('Date')
    values = owner_data['Value'].values
    
    # Only test if we have enough data points
    if len(values) >= MIN_MONTHS_FOR_STATIONARITY:
        logger.info(f"Testing stationarity for owner: {owner}")
        is_stationary, p_value = check_stationarity(values, owner)
        stationarity_results[owner] = {
            'is_stationary': is_stationary,
            'p_value': p_value,
            'data_points': len(values)
        }
    else:
        logger.warning(f"Owner {owner} has only {len(values)} months of data, not enough for stationarity test.")
        print(f"Owner {owner} has only {len(values)} months of data, not enough for stationarity test.")
        stationarity_results[owner] = {
            'is_stationary': None,
            'p_value': None,
            'data_points': len(values)
        }

# Function to analyze and plot ACF and PACF
def analyze_acf_pacf(timeseries, owner_name, max_lags=MAX_LAGS_DEFAULT):
    """
    Analyze and plot ACF and PACF to determine ARIMA order
    """
    logger.info(f"Analyzing ACF/PACF for owner: {owner_name}, max_lags: {max_lags}")
    
    # Compute ACF and PACF
    acf_values = acf(timeseries, nlags=max_lags, fft=True)
    pacf_values = pacf(timeseries, nlags=max_lags, method='ols')
    
    # Plot
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=FIGSIZE_ACF_PACF)
    
    # ACF plot
    plot_acf(timeseries, ax=ax1, lags=max_lags)
    ax1.set_title(f'Autocorrelation Function for Owner: {owner_name}')
    
    # PACF plot
    plot_pacf(timeseries, ax=ax2, lags=max_lags)
    ax2.set_title(f'Partial Autocorrelation Function for Owner: {owner_name}')
    
    plt.tight_layout()
    display(plt.gcf())
    plt.close()
    
    # Find significant lags (95% confidence)
    significance_level = 1.96/np.sqrt(len(timeseries))
    
    # Significant lags in ACF (for MA/q order)
    significant_acf = [i for i in range(1, max_lags + 1) if abs(acf_values[i]) > significance_level]
    
    # Significant lags in PACF (for AR/p order)
    significant_pacf = [i for i in range(1, max_lags + 1) if abs(pacf_values[i]) > significance_level]
    
    print(f"Owner: {owner_name}")
    print(f"Significant lags in ACF (suggests MA/q order): {significant_acf}")
    print(f"Significant lags in PACF (suggests AR/p order): {significant_pacf}")
    
    # Check for seasonality (12 months)
    if max_lags >= 12 and len(timeseries) >= 24:
        seasonal_lag = 12
        if seasonal_lag in significant_acf or seasonal_lag in significant_pacf:
            logger.info(f"Potential yearly seasonality detected at lag {seasonal_lag} for {owner_name}")
            print(f"Potential yearly seasonality detected at lag {seasonal_lag}")
    
    print("-" * 50)
    
    # Suggested order
    p = max(significant_pacf) if significant_pacf else 1
    q = max(significant_acf) if significant_acf else 1
    
    return p, q, acf_values, pacf_values

# Analyze ACF and PACF for each owner with sufficient data
logger.info("Analyzing ACF/PACF for each owner")
acf_pacf_results = {}

for owner in all_owners:
    owner_data = df[df['Owner'] == owner].sort_values('Date')
    values = owner_data['Value'].values
    
    # Only analyze if we have enough data points
    if len(values) >= MIN_MONTHS_FOR_ARIMA:
        print(f"Analyzing ACF/PACF for Owner: {owner} (Months of data: {len(values)})")
        
        # Check if differencing is needed
        is_stationary, _ = stationarity_results[owner]['is_stationary'], stationarity_results[owner]['p_value']
        
        # If not stationary, difference the series
        if not is_stationary:
            logger.info(f"Series for {owner} is not stationary, applying differencing")
            print(f"Series for {owner} is not stationary, applying differencing")
            values_diff = np.diff(values)
            p, q, acf_vals, pacf_vals = analyze_acf_pacf(values_diff, f"{owner} (differenced)")
            d = 1
        else:
            p, q, acf_vals, pacf_vals = analyze_acf_pacf(values, owner)
            d = 0
            
        # For monthly data, we might need higher max_lags to catch seasonality
        if len(values) >= 36:  # If we have at least 3 years of data
            logger.info(f"Checking for seasonality with additional lags for {owner}")
            p_seasonal, q_seasonal, _, _ = analyze_acf_pacf(values if is_stationary else values_diff, 
                                                         f"{owner} (seasonal check)", 
                                                         max_lags=MAX_LAGS_SEASONAL)
            # Use the higher of the two if seasonal analysis found something
            p = max(p, p_seasonal) if p_seasonal > p else p
            q = max(q, q_seasonal) if q_seasonal > q else q
            
        acf_pacf_results[owner] = {
            'p': p,
            'd': d,
            'q': q,
            'acf_values': acf_vals,
            'pacf_values': pacf_vals
        }
        
        logger.info(f"Suggested ARIMA order for {owner}: ({p}, {d}, {q})")
        print(f"Suggested ARIMA order for {owner}: ({p}, {d}, {q})")
    else:
        logger.warning(f"Owner {owner} has only {len(values)} months of data, not enough for robust ACF/PACF analysis.")
        print(f"Owner {owner} has only {len(values)} months of data, not enough for robust ACF/PACF analysis.")
        acf_pacf_results[owner] = None

# Train ARIMA models for owners with sufficient data
logger.info("Training ARIMA models for eligible owners")
arima_results = {}

for owner in all_owners:
    owner_data = df[df['Owner'] == owner].sort_values('Date')
    values = owner_data['Value'].values
    dates = owner_data['Date'].values
    
    # Only attempt ARIMA if we have enough data points
    if len(values) >= MIN_MONTHS_FOR_ARIMA and acf_pacf_results[owner] is not None:
        logger.info(f"Training ARIMA model for Owner: {owner}")
        print(f"Training ARIMA model for Owner: {owner}")
        
        # Get suggested order
        p, d, q = acf_pacf_results[owner]['p'], acf_pacf_results[owner]['d'], acf_pacf_results[owner]['q']
        
        try:
            # Train ARIMA model
            model = ARIMA(values, order=(p, d, q))
            model_fit = model.fit()
            
            # Print model summary
            print(f"ARIMA model summary for Owner: {owner}")
            print(model_fit.summary())
            
            arima_results[owner] = {
                'model_fit': model_fit,
                'order': (p, d, q),
                'values': values,
                'dates': dates,
                'model_type': f"ARIMA({p},{d},{q})"
            }
            logger.info(f"Successfully trained ARIMA({p},{d},{q}) for {owner}")
            
        except Exception as e:
            logger.warning(f"Error training ARIMA for {owner}: {str(e)}")
            print(f"Error training ARIMA for {owner}: {str(e)}")
            print("Trying simpler ARIMA(1,1,1) model...")
            
            try:
                # Try with simpler model
                model = ARIMA(values, order=(1, 1, 1))
                model_fit = model.fit()
                
                arima_results[owner] = {
                    'model_fit': model_fit,
                    'order': (1, 1, 1),
                    'values': values,
                    'dates': dates,
                    'model_type': "ARIMA(1,1,1)"
                }
                logger.info(f"Successfully trained simpler ARIMA(1,1,1) for {owner}")
                
            except Exception as e2:
                logger.error(f"Error training simpler ARIMA for {owner}: {str(e2)}")
                print(f"Error training simpler ARIMA for {owner}: {str(e2)}")
                arima_results[owner] = None
    else:
        logger.info(f"Owner {owner} has insufficient data for ARIMA modeling.")
        print(f"Owner {owner} has insufficient data for ARIMA modeling.")
        arima_results[owner] = None

# Train linear regression models for all owners
logger.info("Training Linear Regression models for all owners")
linear_results = {}

for owner in all_owners:
    owner_data = df[df['Owner'] == owner].sort_values('Date')
    values = owner_data['Value'].values
    dates = owner_data['Date'].values
    
    logger.info(f"Training Linear Regression model for Owner: {owner}")
    print(f"Training Linear Regression model for Owner: {owner}")
    
    # For monthly data, convert dates to numeric feature (months since first date)
    first_date = min(dates)
    X = np.array([((d.year - first_date.year) * 12 + d.month - first_date.month) for d in dates]).reshape(-1, 1)
    
    # Fit model
    model = LinearRegression()
    model.fit(X, values)
    
    # Calculate R-squared
    y_pred = model.predict(X)
    ss_total = np.sum((values - np.mean(values))**2)
    ss_residual = np.sum((values - y_pred)**2)
    r_squared = 1 - (ss_residual / ss_total)
    
    print(f"Linear Regression coefficients for {owner}:")
    print(f"Intercept: {model.intercept_:.4f}")
    print(f"Slope (per month): {model.coef_[0]:.4f}")
    print(f"R-squared: {r_squared:.4f}")
    
    linear_results[owner] = {
        'model_fit': model,
        'first_date': first_date,
        'values': values,
        'dates': dates,
        'r_squared': r_squared,
        'model_type': "Linear Regression"
    }
    logger.info(f"Successfully trained Linear Regression for {owner}, R-squared: {r_squared:.4f}")

# Generate initial forecasts for each owner
logger.info(f"Generating {FORECAST_MONTHS}-month initial forecasts for each owner")
initial_forecast_results = {}

# Store model metadata for MLflow tracking
model_metadata = {}

for owner in all_owners:
    logger.info(f"Generating initial forecast for Owner: {owner}")
    print(f"Generating initial forecast for Owner: {owner}")
    
    # Check if we have a valid ARIMA model
    if owner in arima_results and arima_results[owner] is not None:
        logger.info(f"Using {arima_results[owner]['model_type']} model for {owner}")
        print(f"Using {arima_results[owner]['model_type']} model for {owner}")
        
        # Get the model and data
        model_fit = arima_results[owner]['model_fit']
        values = arima_results[owner]['values']
        dates = arima_results[owner]['dates']
        model_type = arima_results[owner]['model_type']
        
        # Store model metadata
        model_metadata[owner] = {
            'model_fit': model_fit,
            'model_type': model_type,
            'framework': 'statsmodels.ARIMA',
            'params': {
                'order': arima_results[owner]['order']
            }
        }
        
        # Generate forecast
        forecast = model_fit.forecast(steps=FORECAST_MONTHS)
        forecast_conf = model_fit.get_forecast(steps=FORECAST_MONTHS)
        conf_int = forecast_conf.conf_int()
        
        # Generate future dates (monthly)
        last_date = dates[-1]
        future_dates = [last_date + relativedelta(months=i+1) for i in range(FORECAST_MONTHS)]
        
        initial_forecast_results[owner] = {
            'forecast': forecast,
            'conf_int': conf_int,
            'future_dates': future_dates,
            'model_type': model_type
        }
    else:
        logger.info(f"Using Linear Regression model for {owner}")
        print(f"Using Linear Regression model for {owner}")
        
        # Get the model and data
        model_fit = linear_results[owner]['model_fit']
        first_date = linear_results[owner]['first_date']
        values = linear_results[owner]['values']
        dates = linear_results[owner]['dates']
        
        # Store model metadata
        model_metadata[owner] = {
            'model_fit': model_fit,
            'model_type': 'Linear Regression',
            'framework': 'sklearn.LinearRegression',
            'params': {
                'fit_intercept': True
            }
        }
        
        # Get the last date
        last_date = dates[-1]
        
        # Generate future months (as X values)
        months_since_first = [
            ((last_date.year - first_date.year) * 12 + last_date.month - first_date.month) + i + 1 
            for i in range(FORECAST_MONTHS)
        ]
        future_X = np.array(months_since_first).reshape(-1, 1)
        
        # Generate forecast
        forecast = model_fit.predict(future_X)
        
        # Generate simple confidence intervals
        # (This is a simplification - not statistically rigorous)
        prediction_std = np.std(values - model_fit.predict(
            np.array([((d.year - first_date.year) * 12 + d.month - first_date.month) for d in dates]).reshape(-1, 1)
        ))
        conf_lower = forecast - Z_VALUE * prediction_std
        conf_upper = forecast + Z_VALUE * prediction_std
        
        # Create a DataFrame similar to ARIMA's conf_int
        conf_int = pd.DataFrame({
            'lower': conf_lower,
            'upper': conf_upper
        })
        
        # Generate future dates (monthly)
        future_dates = [last_date + relativedelta(months=i+1) for i in range(FORECAST_MONTHS)]
        
        initial_forecast_results[owner] = {
            'forecast': forecast,
            'conf_int': conf_int,
            'future_dates': future_dates,
            'model_type': "Linear Regression"
        }

# Reconcile forecasts if 'Total' is present
if is_total_present:
    logger.info("Reconciling forecasts to ensure consistency with 'Total'")
    print("\nReconciling forecasts to ensure consistency with 'Total'...")
    
    # Get total forecast
    total_forecast = initial_forecast_results["Total"]["forecast"]
    
    # Get sum of individual forecasts
    individual_forecasts = np.zeros(FORECAST_MONTHS)
    for owner in other_owners:
        individual_forecasts += initial_forecast_results[owner]["forecast"]
    
    # Calculate discrepancy
    discrepancy = total_forecast - individual_forecasts
    print(f"Discrepancy between 'Total' and sum of individuals: {discrepancy}")
    
    # Reconciliation methods
    reconciled_forecast_results = {}
    reconciled_forecast_results["Total"] = initial_forecast_results["Total"]  # Keep original Total
    
    if RECONCILIATION_METHOD == "proportional":
        # Proportional reconciliation
        logger.info("Using proportional reconciliation method")
        print("Using proportional reconciliation method")
        
        for month in range(FORECAST_MONTHS):
            # Skip reconciliation if sum is close to zero to avoid division by zero
            if abs(individual_forecasts[month]) < 1e-10:
                for owner in other_owners:
                    if "reconciled_forecast" not in reconciled_forecast_results.get(owner, {}):
                        reconciled_forecast_results[owner] = {
                            "reconciled_forecast": initial_forecast_results[owner]["forecast"].copy(),
                            "future_dates": initial_forecast_results[owner]["future_dates"],
                            "model_type": initial_forecast_results[owner]["model_type"],
                            "initial_forecast": initial_forecast_results[owner]["forecast"].copy(),
                            "conf_int": initial_forecast_results[owner]["conf_int"]
                        }
                continue
            
            # Calculate proportional adjustment for each owner
            for owner in other_owners:
                if "reconciled_forecast" not in reconciled_forecast_results.get(owner, {}):
                    reconciled_forecast_results[owner] = {
                        "reconciled_forecast": initial_forecast_results[owner]["forecast"].copy(),
                        "future_dates": initial_forecast_results[owner]["future_dates"],
                        "model_type": initial_forecast_results[owner]["model_type"],
                        "initial_forecast": initial_forecast_results[owner]["forecast"].copy(),
                        "conf_int": initial_forecast_results[owner]["conf_int"]
                    }
                
                # Proportional adjustment
                owner_forecast = initial_forecast_results[owner]["forecast"][month]
                proportion = owner_forecast / individual_forecasts[month] if individual_forecasts[month] != 0 else 0
                adjustment = discrepancy[month] * proportion
                reconciled_forecast_results[owner]["reconciled_forecast"][month] += adjustment
    
    elif RECONCILIATION_METHOD == "weight_forecast":
        # Weight by forecast uncertainty (using confidence interval width)
        logger.info("Using uncertainty-weighted reconciliation method")
        print("Using uncertainty-weighted reconciliation method")
        
        for month in range(FORECAST_MONTHS):
            # Calculate weights based on forecast uncertainty
            weights = {}
            total_weight = 0
            
            for owner in other_owners:
                conf_int = initial_forecast_results[owner]["conf_int"]
                uncertainty = conf_int.iloc[month, 1] - conf_int.iloc[month, 0]  # Upper - Lower
                
                # Inverse of uncertainty as weight (more certain forecasts get higher weight)
                weight = 1.0 / uncertainty if uncertainty > 0 else 1.0
                weights[owner] = weight
                total_weight += weight
            
            # Normalize weights
            for owner in weights:
                weights[owner] /= total_weight
            
            # Apply weighted adjustments
            for owner in other_owners:
                if "reconciled_forecast" not in reconciled_forecast_results.get(owner, {}):
                    reconciled_forecast_results[owner] = {
                        "reconciled_forecast": initial_forecast_results[owner]["forecast"].copy(),
                        "future_dates": initial_forecast_results[owner]["future_dates"],
                        "model_type": initial_forecast_results[owner]["model_type"],
                        "initial_forecast": initial_forecast_results[owner]["forecast"].copy(),
                        "conf_int": initial_forecast_results[owner]["conf_int"]
                    }
                
                # Weighted adjustment
                adjustment = discrepancy[month] * weights[owner]
                reconciled_forecast_results[owner]["reconciled_forecast"][month] += adjustment
    
    elif RECONCILIATION_METHOD == "weight_history":
        # Weight by historical share
        logger.info("Using historical share-weighted reconciliation method")
        print("Using historical share-weighted reconciliation method")
        
        # Calculate historical share for each owner
        total_data = df[df['Owner'] == "Total"].sort_values('Date')
        historical_shares = {}
        
        for owner in other_owners:
            owner_data = df[df['Owner'] == owner].sort_values('Date')
            # Merge on date to ensure alignment
            merged_data = pd.merge(owner_data, total_data, on='Date', suffixes=('_owner', '_total'))
            # Calculate historical share
            merged_data['share'] = merged_data['Value_owner'] / merged_data['Value_total']
            # Use average share over the last year or all available data if less
            last_n = min(12, len(merged_data))
            avg_share = merged_data['share'].tail(last_n).mean()
            historical_shares[owner] = avg_share
        
        # Normalize shares to sum to 1
        share_sum = sum(historical_shares.values())
        for owner in historical_shares:
            historical_shares[owner] /= share_sum
        
        # Apply weighted adjustments
        for owner in other_owners:
            if "reconciled_forecast" not in reconciled_forecast_results.get(owner, {}):
                reconciled_forecast_results[owner] = {
                    "reconciled_forecast": initial_forecast_results[owner]["forecast"].copy(),
                    "future_dates": initial_forecast_results[owner]["future_dates"],
                    "model_type": initial_forecast_results[owner]["model_type"],
                    "initial_forecast": initial_forecast_results[owner]["forecast"].copy(),
                    "conf_int": initial_forecast_results[owner]["conf_int"]
                }
            
            # Apply historical share-based adjustment for each month
            for month in range(FORECAST_MONTHS):
                adjustment = discrepancy[month] * historical_shares[owner]
                reconciled_forecast_results[owner]["reconciled_forecast"][month] += adjustment
    
    else:
        logger.warning(f"Unknown reconciliation method: {RECONCILIATION_METHOD}. Using initial forecasts.")
        print(f"Unknown reconciliation method: {RECONCILIATION_METHOD}. Using initial forecasts.")
        reconciled_forecast_results = initial_forecast_results
    
    # Verify reconciliation
    reconciled_sum = np.zeros(FORECAST_MONTHS)
    for owner in other_owners:
        reconciled_sum += reconciled_forecast_results[owner]["reconciled_forecast"]
    
    # Display reconciliation results
    reconciliation_error = total_forecast - reconciled_sum
    print("\nReconciliation verification:")
    print(f"Total forecast: {total_forecast}")
    print(f"Sum of reconciled individual forecasts: {reconciled_sum}")
    print(f"Remaining discrepancy: {reconciliation_error}")
    print(f"Max absolute error: {np.max(np.abs(reconciliation_error))}")
    
    # Assign reconciled forecasts to final forecast results
    forecast_results = {}
    for owner in all_owners:
        if owner == "Total":
            forecast_results[owner] = initial_forecast_results[owner]
        else:
            forecast_results[owner] = {
                'forecast': reconciled_forecast_results[owner]["reconciled_forecast"],
                'initial_forecast': initial_forecast_results[owner]["forecast"],
                'conf_int': initial_forecast_results[owner]["conf_int"],
                'future_dates': initial_forecast_results[owner]["future_dates"],
                'model_type': initial_forecast_results[owner]["model_type"]
            }
else:
    # If no "Total" owner, use initial forecasts
    forecast_results = initial_forecast_results

# Plot forecasts for each owner
logger.info("Plotting forecasts for each owner")
for owner in all_owners:
    # Get owner data
    owner_data = df[df['Owner'] == owner].sort_values('Date')
    dates = owner_data['Date']
    values = owner_data['Value']
    
    # Get forecast data
    forecast = forecast_results[owner]['forecast']
    conf_int = forecast_results[owner]['conf_int']
    future_dates = forecast_results[owner]['future_dates']
    model_type = forecast_results[owner]['model_type']
    
    # Create plot
    plt.figure(figsize=FIGSIZE_TIMESERIES)
    
    # Plot historical data
    plt.plot(dates, values, label='Historical Data', marker='o', color='blue')
    
    # Plot forecast
    plt.plot(future_dates, forecast, label=f'Forecast ({model_type})', 
             color='red', marker='x', linestyle='--')
    
    # Plot initial forecast if reconciled
    if is_total_present and owner != "Total" and 'initial_forecast' in forecast_results[owner]:
        initial_forecast = forecast_results[owner]['initial_forecast']
        plt.plot(future_dates, initial_forecast, label=f'Initial Forecast (pre-reconciliation)', 
                 color='green', marker='+', linestyle=':')
    
    # Plot confidence interval
    if isinstance(conf_int, pd.DataFrame):
        plt.fill_between(future_dates, 
                         conf_int['lower'], 
                         conf_int['upper'], 
                         color='red', alpha=0.2)
    
    # Add labels and title
    title = f'Monthly Forecast for Owner: {owner} using {model_type}'
    if is_total_present and owner != "Total":
        title += f' (Reconciled using {RECONCILIATION_METHOD})'
    plt.title(title)
    plt.xlabel('Date')
    plt.ylabel('Value')
    plt.grid(True)
    plt.legend()
    
    # Add vertical line at the forecast start
    plt.axvline(x=dates.iloc[-1], color='green', linestyle='--', 
                label='Forecast Start')
    
    # Format date axis to show month-year
    plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%b %Y'))
    plt.gcf().autofmt_xdate()
    
    # Display plot
    display(plt.gcf())
    plt.close()

# Create summary report
logger.info("Creating summary report")
summary_data = []

for owner in all_owners:
    # Get original data
    owner_data = df[df['Owner'] == owner]
    
    # Get forecast data
    forecast = forecast_results[owner]['forecast']
    model_type = forecast_results[owner]['model_type']
    future_dates = forecast_results[owner]['future_dates']
    
    # Get initial forecast if reconciled
    is_reconciled = is_total_present and owner != "Total" and 'initial_forecast' in forecast_results[owner]
    if is_reconciled:
        initial_forecast = forecast_results[owner]['initial_forecast']
    
    # Calculate growth metrics
    last_value = owner_data['Value'].iloc[-1]
    forecast_first = forecast[0]  # First month forecast
    forecast_third = forecast[2] if len(forecast) > 2 else np.nan  # 3-month forecast
    forecast_sixth = forecast[5] if len(forecast) > 5 else np.nan  # 6-month forecast
    forecast_last = forecast[-1]  # 12-month forecast
    
    # Calculate percentage changes
    pct_change_1m = ((forecast_first - last_value) / last_value) * 100 if last_value != 0 else np.inf
    pct_change_3m = ((forecast_third - last_value) / last_value) * 100 if last_value != 0 else np.inf
    pct_change_6m = ((forecast_sixth - last_value) / last_value) * 100 if last_value != 0 else np.inf
    pct_change_12m = ((forecast_last - last_value) / last_value) * 100 if last_value != 0 else np.inf
    
    # Prepare summary data
    summary_item = {
        'Owner': owner,
        'Model_Type': model_type,
        'Months_of_Data': len(owner_data),
        'Last_Actual_Value': round(last_value, 2),
        'Forecast_1M': round(forecast_first, 2),
        'Forecast_3M': round(forecast_third, 2) if not np.isnan(forecast_third) else np.nan,
        'Forecast_6M': round(forecast_sixth, 2) if not np.isnan(forecast_sixth) else np.nan,
        'Forecast_12M': round(forecast_last, 2),
        '%_Change_1M': round(pct_change_1m, 2),
        '%_Change_3M': round(pct_change_3m, 2) if not np.isnan(forecast_third) else np.nan,
        '%_Change_6M': round(pct_change_6m, 2) if not np.isnan(forecast_sixth) else np.nan,
        '%_Change_12M': round(pct_change_12m, 2)
    }
    
    # Add reconciliation info if applicable
    if is_reconciled:
        summary_item['Initial_Forecast_1M'] = round(initial_forecast[0], 2)
        summary_item['Initial_Forecast_12M'] = round(initial_forecast[-1], 2)
        summary_item['Reconciliation_Adjust_1M'] = round(forecast_first - initial_forecast[0], 2)
        summary_item['Reconciliation_Adjust_12M'] = round(forecast_last - initial_forecast[-1], 2)
    
    summary_data.append(summary_item)

# Create DataFrame and display summary
summary_df = pd.DataFrame(summary_data)
print("Forecast Summary Report:")
display(summary_df)

# Create detailed forecast tables for each owner
logger.info("Creating detailed forecast tables for each owner")
for owner in all_owners:
    # Get forecast data
    forecast = forecast_results[owner]['forecast']
    future_dates = forecast_results[owner]['future_dates']
    model_type = forecast_results[owner]['model_type']
    
    # Create DataFrame for forecasts
    forecast_data = {
        'Month': [d.strftime('%Y-%m') for d in future_dates],
        'Forecasted_Value': forecast,
        'Model_Type': model_type
    }
    
    # Add initial forecast if reconciled
    if is_total_present and owner != "Total" and 'initial_forecast' in forecast_results[owner]:
        forecast_data['Initial_Forecast'] = forecast_results[owner]['initial_forecast']
        forecast_data['Adjustment'] = forecast - forecast_results[owner]['initial_forecast']
    
    forecast_df = pd.DataFrame(forecast_data)
    
    # Display
    print(f"Detailed monthly forecast for {owner} using {model_type}:")
    display(forecast_df)

# Optional: Seasonal analysis for owners with sufficient data
logger.info("Performing seasonal analysis for owners with sufficient data")
for owner in all_owners:
    owner_data = df[df['Owner'] == owner].sort_values('Date')
    
    # Only analyze if we have enough data (at least 2 years)
    if len(owner_data) >= 24:
        logger.info(f"Performing seasonal analysis for Owner: {owner}")
        print(f"Seasonal analysis for Owner: {owner}")
        
        # Create a month column
        owner_data['Month'] = owner_data['Date'].dt.month
        
        # Group by month and calculate average
        monthly_avg = owner_data.groupby('Month')['Value'].mean().reset_index()
        monthly_avg['Month_Name'] = monthly_avg['Month'].apply(lambda x: datetime(2000, x, 1).strftime('%b'))
        
        # Plot monthly averages
        plt.figure(figsize=(12, 6))
        plt.bar(monthly_avg['Month_Name'], monthly_avg['Value'], color='skyblue')
        plt.title(f'Monthly Seasonal Pattern for Owner: {owner}')
        plt.xlabel('Month')
        plt.ylabel('Average Value')
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # Display plot
        display(plt.gcf())
        plt.close()
        
        # Identify peak and trough months
        peak_month = monthly_avg.loc[monthly_avg['Value'].idxmax()]
        trough_month = monthly_avg.loc[monthly_avg['Value'].idxmin()]
        
        print(f"Peak month: {peak_month['Month_Name']} (Average: {peak_month['Value']:.2f})")
        print(f"Trough month: {trough_month['Month_Name']} (Average: {trough_month['Value']:.2f})")
        print("-" * 50)
        
        # Display monthly average data
        print("Monthly average values:")
        display(monthly_avg[['Month_Name', 'Value']].sort_values('Month'))

# Output model_metadata dictionary that can be used for MLflow tracking
logger.info("Model training and forecasting complete")
print("\nModel metadata for MLflow tracking:")
for owner, metadata in model_metadata.items():
    print(f"Owner: {owner}, Model Type: {metadata['model_type']}, Framework: {metadata['framework']}")

# Return the model_metadata dictionary for use in the MLflow tracking code block
model_metadata
