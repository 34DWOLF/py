```python
import pandas as pd
import numpy as np
from pycaret.time_series import TSForecastingExperiment
from sklearn.metrics import mean_squared_error
from joblib import Parallel, delayed
import warnings
warnings.filterwarnings('ignore')

# ===== PARAMETERS =====
TARGET_COLUMN = 'A'
REGRESSORS = ['B', 'C', 'D', 'E', 'F']
FORECAST_HORIZON = 12
# ======================

# Load your data
# df = pd.read_csv('your_data.csv')
# Example: df with columns ['Date', 'A', 'B', 'C', 'D', 'E', 'F']

# Ensure Date is datetime and set as index
df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values('Date').reset_index(drop=True)
df = df.set_index('Date')

# Ensure all columns are numeric
for col in df.columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Initialize experiment
exp = TSForecastingExperiment()

# Setup with all columns (PyCaret 3.3.2 auto-detects non-target columns as exogenous)
exp.setup(
    data=df,
    target=TARGET_COLUMN,
    fh=FORECAST_HORIZON,
    numeric_imputation_exogenous='ffill',
    fold=3,
    session_id=42,
    verbose=False
)

# Compare models and add nRMSE
best_models = exp.compare_models(sort='RMSE', n_select=10)
leaderboard = exp.pull()

# Calculate nRMSE
y_train = exp.get_config('y_train')
y_range = float(y_train.max() - y_train.min())
leaderboard['nRMSE'] = pd.to_numeric(leaderboard['RMSE'], errors='coerce') / y_range
print("\n=== Model Leaderboard with nRMSE ===")
print(leaderboard[['Model', 'RMSE', 'nRMSE', 'MAE', 'MAPE']].to_string())

# Get best model
best_model = exp.automl(optimize='RMSE')
print(f"\n=== Best Model: {type(best_model).__name__} ===")

# Finalize model on full data
final_model = exp.finalize_model(best_model)

# Create future exogenous data (forward fill last values)
last_values = df[REGRESSORS].iloc[-1:]
future_exog = pd.concat([last_values] * FORECAST_HORIZON, ignore_index=True)
future_index = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=FORECAST_HORIZON, freq='D')
future_exog.index = future_index

# Make predictions
try:
    predictions_future = exp.predict_model(final_model, fh=FORECAST_HORIZON, X=future_exog)
    print("\n=== Future Predictions ===")
    print(predictions_future)
except Exception as e:
    print(f"Future prediction error: {e}")

# Feature Importance - Model-based
print("\n=== Model-Based Feature Importance ===")
try:
    if hasattr(final_model, 'feature_importances_'):
        importances = final_model.feature_importances_
        importance_df = pd.DataFrame({
            'Feature': REGRESSORS,
            'Importance': importances
        }).sort_values('Importance', ascending=False)
        print(importance_df.to_string())
    else:
        print("Model does not have feature_importances_ attribute")
except Exception as e:
    print(f"Could not extract model-based importance: {e}")

# Permutation Importance - Skip due to compatibility issues
print("\n=== Permutation Feature Importance ===")
print("Skipped due to PyCaret 3.3.2 compatibility")

# Leave-One-Regressor-Out Analysis
print("\n=== Leave-One-Regressor-Out Analysis ===")

# Baseline (all regressors)
exp_baseline = TSForecastingExperiment()
exp_baseline.setup(
    data=df,
    target=TARGET_COLUMN,
    fh=FORECAST_HORIZON,
    fold=3,
    session_id=42,
    verbose=False
)
baseline_model = exp_baseline.automl(optimize='RMSE')
baseline_results = exp_baseline.pull()
baseline_rmse = float(pd.to_numeric(baseline_results.iloc[0]['RMSE'], errors='coerce'))
baseline_nrmse = baseline_rmse / y_range

print(f"Baseline RMSE (all regressors): {baseline_rmse:.4f}")
print(f"Baseline nRMSE (all regressors): {baseline_nrmse:.4f}")

def evaluate_without_regressor(regressor, df, target, all_regressors, fh, y_range):
    """Train model without one regressor and return RMSE"""
    try:
        remaining_regressors = [r for r in all_regressors if r != regressor]
        
        if len(remaining_regressors) == 0:
            return None, None
        
        # Create df without the excluded regressor
        df_temp = df[[target] + remaining_regressors].copy()
        
        exp_temp = TSForecastingExperiment()
        exp_temp.setup(
            data=df_temp,
            target=target,
            fh=fh,
            fold=3,
            session_id=42,
            verbose=False
        )
        
        model_temp = exp_temp.automl(optimize='RMSE')
        results_temp = exp_temp.pull()
        rmse_temp = float(pd.to_numeric(results_temp.iloc[0]['RMSE'], errors='coerce'))
        nrmse_temp = rmse_temp / y_range
        
        return rmse_temp, nrmse_temp
    except Exception as e:
        print(f"Error evaluating without {regressor}: {e}")
        return None, None

# Parallel evaluation
results_parallel = Parallel(n_jobs=-1, verbose=10)(
    delayed(evaluate_without_regressor)(reg, df, TARGET_COLUMN, REGRESSORS, FORECAST_HORIZON, y_range)
    for reg in REGRESSORS
)

# Compile results
impact_results = []
for i, regressor in enumerate(REGRESSORS):
    rmse_without, nrmse_without = results_parallel[i]
    
    if rmse_without is not None and nrmse_without is not None:
        delta_rmse = float(rmse_without - baseline_rmse)
        delta_nrmse = float(nrmse_without - baseline_nrmse)
        
        impact_results.append({
            'Regressor': regressor,
            'RMSE_without': float(rmse_without),
            'RMSE_baseline': float(baseline_rmse),
            'ΔRMSE': delta_rmse,
            'nRMSE_without': float(nrmse_without),
            'nRMSE_baseline': float(baseline_nrmse),
            'ΔnRMSE': delta_nrmse
        })

if len(impact_results) > 0:
    impact_df = pd.DataFrame(impact_results).sort_values('ΔnRMSE', ascending=False)
    print("\n=== Regressor Impact Summary (sorted by ΔnRMSE) ===")
    print(impact_df.to_string(index=False))
else:
    print("\n=== No regressor impact results available ===")

print("\n=== Analysis Complete ===")
```