# STEP 1: Imports
import pandas as pd
import numpy as np
from pycaret.time_series import TSForecastingExperiment
from sklearn.inspection import permutation_importance
from joblib import Parallel, delayed
import warnings
warnings.filterwarnings("ignore")

# STEP 2: Load & Prepare Data
df = pd.DataFrame({
    'Date': pd.date_range(start='2015-01-01', periods=100, freq='MS'),
    'A': np.linspace(0, 100, 100) + np.random.normal(0, 5, 100),
    'B': np.linspace(10, 110, 100) + np.random.normal(0, 2, 100),
    'C': np.linspace(5, 105, 100),
    'D': np.linspace(2, 102, 100),
    'E': np.linspace(50, 150, 100),
    'F': np.linspace(80, 180, 100),
})

df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values('Date').set_index('Date')
df = df.asfreq('MS')

target_col = 'A'
regressors = ['B', 'C', 'D', 'E', 'F']
forecast_horizon = 12
target_mean = df[target_col].mean()

# STEP 3: Setup PyCaret (v3.3.2 syntax)
exp = TSForecastingExperiment()
exp.setup(
    data=df,               # target + regressors together
    target=target_col,     # specify which column to forecast
    fh=forecast_horizon,
    session_id=42,
    fold_strategy='sliding',
    numeric_imputation_target='ffill',
    numeric_imputation_exogenous='ffill',
    enforce_exogenous=True,
    verbose=True
)

# STEP 4: Model Comparison & nRMSE
best_model = exp.compare_models(sort='RMSE')
leaderboard = exp.pull()
leaderboard['nRMSE'] = leaderboard['RMSE'] / target_mean

print("\nMODEL LEADERBOARD WITH nRMSE")
print(leaderboard[['Model', 'RMSE', 'nRMSE', 'MAE', 'MAPE', 'R2']])

final_model = exp.finalize_model(best_model)

# STEP 5: Forecast
forecast = exp.predict_model(final_model, fh=forecast_horizon)
print("\nFORECAST RESULTS")
print(forecast)

exp.plot_model(final_model, plot='forecast')
exp.plot_model(final_model, plot='diagnostics')

# STEP 6: Feature Importance (Model-Based)
print("\nMODEL-BASED FEATURE IMPORTANCE")
try:
    exp.plot_model(final_model, plot='feature_importances')
except Exception as e:
    print("Model-based feature importance not supported:", e)

# STEP 7: Permutation Importance
print("\nPERMUTATION FEATURE IMPORTANCE")
try:
    X_test = exp.get_config('X_test')
    y_test = exp.get_config('y_test')
    r = permutation_importance(
        final_model,
        X_test,
        y_test,
        n_repeats=20,
        random_state=42,
        n_jobs=-1
    )
    sorted_idx = r.importances_mean.argsort()[::-1]
    for idx in sorted_idx:
        print(f"{X_test.columns[idx]}: {r.importances_mean[idx]:.4f}")
except Exception as e:
    print("Permutation importance failed:", e)

# STEP 8: Parallel Leave-One-Regressor-Out Impact (with nRMSE)
print("\nPARALLEL LEAVE-ONE-REGRESSOR-OUT IMPACT ANALYSIS (with nRMSE)")
base_rmse = leaderboard.iloc[0]['RMSE']
base_nrmse = base_rmse / target_mean

def evaluate_without_regressor(reg):
    df_reduced = df.drop(columns=[reg])
    exp_tmp = TSForecastingExperiment()
    exp_tmp.setup(
        data=df_reduced,
        target=target_col,
        fh=forecast_horizon,
        session_id=42,
        fold_strategy='sliding',
        numeric_imputation_target='ffill',
        numeric_imputation_exogenous='ffill',
        enforce_exogenous=True,
        verbose=False
    )
    m = exp_tmp.create_model(best_model)
    exp_tmp.finalize_model(m)
    rmse = exp_tmp.pull().iloc[0]['RMSE']
    nrmse = rmse / target_mean
    return (reg, rmse, rmse - base_rmse, nrmse, nrmse - base_nrmse)

impact_results = Parallel(n_jobs=-1, backend="loky")(
    delayed(evaluate_without_regressor)(reg) for reg in regressors
)

impact_df = pd.DataFrame(
    impact_results,
    columns=['Regressor', 'RMSE_without', 'ΔRMSE', 'nRMSE_without', 'ΔnRMSE']
).sort_values('ΔnRMSE', ascending=False)

print("\nREGRESSOR IMPACT SUMMARY (with nRMSE)")
print(impact_df)
