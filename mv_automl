```python
import pandas as pd
import numpy as np
from pycaret.time_series import TSForecastingExperiment
from sklearn.metrics import mean_squared_error
from sklearn.inspection import permutation_importance
from joblib import Parallel, delayed
import warnings
warnings.filterwarnings('ignore')

# ===== PARAMETERS =====
TARGET_COLUMN = 'A'
REGRESSORS = ['B', 'C', 'D', 'E', 'F']
FORECAST_HORIZON = 12
# ======================

# Load your data
# df = pd.read_csv('your_data.csv')
# Example: df with columns ['Date', 'A', 'B', 'C', 'D', 'E', 'F']

# Ensure Date is datetime
df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values('Date').reset_index(drop=True)

# Initialize experiment
exp = TSForecastingExperiment()

# Setup with all columns (PyCaret 3.3.2 auto-detects non-target columns as exogenous)
exp.setup(
    data=df,
    target=TARGET_COLUMN,
    fh=FORECAST_HORIZON,
    numeric_imputation_exogenous='ffill',
    fold=3,
    session_id=42,
    verbose=False
)

# Compare models and add nRMSE
best_models = exp.compare_models(sort='RMSE', n_select=10)
leaderboard = exp.pull()

# Calculate nRMSE
y_train = exp.get_config('y_train')
y_range = y_train.max() - y_train.min()
leaderboard['nRMSE'] = leaderboard['RMSE'] / y_range
print("\n=== Model Leaderboard with nRMSE ===")
print(leaderboard[['Model', 'RMSE', 'nRMSE', 'MAE', 'MAPE']].to_string())

# Get best model
best_model = exp.automl(optimize='RMSE')
print(f"\n=== Best Model: {type(best_model).__name__} ===")

# Finalize model on full data
final_model = exp.finalize_model(best_model)

# Make predictions
predictions_holdout = exp.predict_model(final_model)
predictions_future = exp.predict_model(final_model, fh=FORECAST_HORIZON)

print("\n=== Future Predictions ===")
print(predictions_future)

# Feature Importance - Model-based
print("\n=== Model-Based Feature Importance ===")
try:
    if hasattr(final_model, 'feature_importances_'):
        importances = final_model.feature_importances_
        importance_df = pd.DataFrame({
            'Feature': REGRESSORS,
            'Importance': importances
        }).sort_values('Importance', ascending=False)
        print(importance_df.to_string())
    else:
        print("Model does not have feature_importances_ attribute")
except Exception as e:
    print(f"Could not extract model-based importance: {e}")

# Permutation Importance
print("\n=== Permutation Feature Importance ===")
try:
    y_val = exp.get_config('y_val')
    X_val = exp.get_config('X_val')
    
    perm_importance = permutation_importance(
        final_model, X_val, y_val, n_repeats=10, random_state=42, scoring='neg_mean_squared_error'
    )
    
    perm_df = pd.DataFrame({
        'Feature': X_val.columns,
        'Importance': perm_importance.importances_mean,
        'Std': perm_importance.importances_std
    }).sort_values('Importance', ascending=False)
    print(perm_df.to_string())
except Exception as e:
    print(f"Could not compute permutation importance: {e}")

# Leave-One-Regressor-Out Analysis
print("\n=== Leave-One-Regressor-Out Analysis ===")

# Baseline (all regressors)
exp_baseline = TSForecastingExperiment()
exp_baseline.setup(
    data=df,
    target=TARGET_COLUMN,
    fh=FORECAST_HORIZON,
    fold=3,
    session_id=42,
    verbose=False
)
baseline_model = exp_baseline.automl(optimize='RMSE')
baseline_results = exp_baseline.pull()
baseline_rmse = baseline_results.iloc[0]['RMSE']
baseline_nrmse = baseline_rmse / y_range

print(f"Baseline RMSE (all regressors): {baseline_rmse:.4f}")
print(f"Baseline nRMSE (all regressors): {baseline_nrmse:.4f}")

def evaluate_without_regressor(regressor, df, target, all_regressors, fh, y_range):
    """Train model without one regressor and return RMSE"""
    remaining_regressors = [r for r in all_regressors if r != regressor]
    
    if len(remaining_regressors) == 0:
        return None, None
    
    # Create df without the excluded regressor
    df_temp = df[['Date', target] + remaining_regressors].copy()
    
    exp_temp = TSForecastingExperiment()
    exp_temp.setup(
        data=df_temp,
        target=target,
        fh=fh,
        fold=3,
        session_id=42,
        verbose=False
    )
    
    model_temp = exp_temp.automl(optimize='RMSE')
    results_temp = exp_temp.pull()
    rmse_temp = results_temp.iloc[0]['RMSE']
    nrmse_temp = rmse_temp / y_range
    
    return rmse_temp, nrmse_temp

# Parallel evaluation
results_parallel = Parallel(n_jobs=-1, verbose=10)(
    delayed(evaluate_without_regressor)(reg, df, TARGET_COLUMN, REGRESSORS, FORECAST_HORIZON, y_range)
    for reg in REGRESSORS
)

# Compile results
impact_results = []
for i, regressor in enumerate(REGRESSORS):
    rmse_without, nrmse_without = results_parallel[i]
    
    if rmse_without is not None:
        delta_rmse = rmse_without - baseline_rmse
        delta_nrmse = nrmse_without - baseline_nrmse
        
        impact_results.append({
            'Regressor': regressor,
            'RMSE_without': rmse_without,
            'RMSE_baseline': baseline_rmse,
            'ΔRMSE': delta_rmse,
            'nRMSE_without': nrmse_without,
            'nRMSE_baseline': baseline_nrmse,
            'ΔnRMSE': delta_nrmse
        })

impact_df = pd.DataFrame(impact_results).sort_values('ΔnRMSE', ascending=False)

print("\n=== Regressor Impact Summary (sorted by ΔnRMSE) ===")
print(impact_df.to_string(index=False))

print("\n=== Analysis Complete ===")
```